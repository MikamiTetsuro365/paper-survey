# Aggregated Residual Transformation for Deep Neural Networks

## 1. どんなもの？

入力に対し"cardinality"を元に様々な変換処理を施し，それらを集約するブロックを重ねることでハイパーパラメータを減らしたResNeXtを提案．ILSVRCでは2位という成績を残した．

## 2. 先行研究と比べてどこがすごいの？

## 3. 技術や手法の"キモ"はどこにある？

## 4. どうやって有効だと検証した？

## 5. 議論はあるか？

## 6. 次に読むべき論文はあるか？

### 論文情報・リンク

* [Xie, Saining, et al. "Aggregated residual transformations for deep neural networks." arXiv preprint arXiv:1611.05431 (2016).](https://arxiv.org/pdf/1611.05431)
