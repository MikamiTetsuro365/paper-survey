<?xml version="1.0" encoding="utf-8"?><feed xmlns="http://www.w3.org/2005/Atom" ><generator uri="https://jekyllrb.com/" version="3.6.2">Jekyll</generator><link href="https://shunk031.github.io/paper-survey/feed.xml" rel="self" type="application/atom+xml" /><link href="https://shunk031.github.io/paper-survey/" rel="alternate" type="text/html" /><updated>2018-06-03T07:18:24+00:00</updated><id>https://shunk031.github.io/paper-survey/</id><title type="html">Paper Survey</title><subtitle>Survey of previous research and related works on machine learning (especially Deep Learning) in Japanese
</subtitle><entry><title type="html">Skin Lesion Analysis Toward Melanoma Detection: A Challenge at the 2017 International Symposium on Biomedical Imaging (ISBI), Hosted by the International Skin Imaging Collaboration (ISIC)</title><link href="https://shunk031.github.io/paper-survey/summary/others/Skin-Lesion-Analysis-Toward-Melanoma-Detection-A-Challenge-at-the-2017-International-Symposium-on-Biomedical-Imaging-ISBI-Hosted-by-the-International-Skin-Imaging-Collaboration-ISIC" rel="alternate" type="text/html" title="Skin Lesion Analysis Toward Melanoma Detection: A Challenge at the 2017 International Symposium on Biomedical Imaging (ISBI), Hosted by the International Skin Imaging Collaboration (ISIC) " /><published>2018-06-03T00:00:00+00:00</published><updated>2018-06-03T00:00:00+00:00</updated><id>https://shunk031.github.io/paper-survey/summary/others/Skin-Lesion-Analysis-Toward-Melanoma-Detection-A-Challenge-at-the-2017-International-Symposium-on-Biomedical-Imaging-ISBI-Hosted-by-the-International-Skin-Imaging-Collaboration-ISIC</id><content type="html" xml:base="https://shunk031.github.io/paper-survey/summary/others/Skin-Lesion-Analysis-Toward-Melanoma-Detection-A-Challenge-at-the-2017-International-Symposium-on-Biomedical-Imaging-ISBI-Hosted-by-the-International-Skin-Imaging-Collaboration-ISIC">&lt;h2 id=&quot;1-どんなもの&quot;&gt;1. どんなもの？&lt;/h2&gt;

&lt;p&gt;ISIC2017で行われたメラノーマ画像の分析チャレンジの内容をまとめたもの&lt;/p&gt;

&lt;h2 id=&quot;2-先行研究と比べてどこがすごい&quot;&gt;2. 先行研究と比べてどこがすごい？&lt;/h2&gt;

&lt;ul&gt;
  &lt;li&gt;ISIC2017では3種類のタスクが公開された
    &lt;ul&gt;
      &lt;li&gt;Lesion Segmentation Task&lt;/li&gt;
      &lt;li&gt;Dermoscopic Feature Classification&lt;/li&gt;
      &lt;li&gt;Disease Classification Task
        &lt;ul&gt;
          &lt;li&gt;3カテゴリ (melanoma, nevus, seborrheic keratosis) をそれぞれ分類するタスク&lt;/li&gt;
          &lt;li&gt;melanoma (train: 374, val: 30, test: 117)&lt;/li&gt;
          &lt;li&gt;nevus (train: 1372, val: 78, test: 393)&lt;/li&gt;
          &lt;li&gt;seborrheic keratosis (train: 254, val: 42, test: 90)&lt;/li&gt;
        &lt;/ul&gt;
      &lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
  &lt;li&gt;データセットは以下から入手できる
    &lt;ul&gt;
      &lt;li&gt;&lt;a href=&quot;http://challenge2017.isic-archive.com/&quot;&gt;http://challenge2017.isic-archive.com/&lt;/a&gt;&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
&lt;/ul&gt;

&lt;h2 id=&quot;3-技術や手法のキモはどこ&quot;&gt;3. 技術や手法のキモはどこ？&lt;/h2&gt;

&lt;ul&gt;
  &lt;li&gt;平均スコアがベストだったモデル
    &lt;ul&gt;
      &lt;li&gt;&lt;a href=&quot;https://arxiv.org/abs/1703.03108&quot;&gt;Matsunaga, Kazuhisa, et al. “Image classification of melanoma, nevus and seborrheic keratosis by deep neural network ensemble.” arXiv preprint arXiv:1703.03108 (2017).&lt;/a&gt;&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
  &lt;li&gt;Melanoma予測精度がベストだったモデル
    &lt;ul&gt;
      &lt;li&gt;&lt;a href=&quot;https://arxiv.org/abs/1703.01976&quot;&gt;Díaz, Iván González. “Incorporating the knowledge of dermatologists to convolutional neural networks for the diagnosis of skin lesions.” arXiv preprint arXiv:1703.01976 (2017).&lt;/a&gt;&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
  &lt;li&gt;Seborrheic keratosis予測精度がベストだったモデル
    &lt;ul&gt;
      &lt;li&gt;&lt;a href=&quot;https://arxiv.org/abs/1703.04819&quot;&gt;Menegola, Afonso, et al. “RECOD titans at ISIC challenge 2017.” arXiv preprint arXiv:1703.04819 (2017).&lt;/a&gt;&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
&lt;/ul&gt;

&lt;h3 id=&quot;予測モデルのトレンド&quot;&gt;予測モデルのトレンド&lt;/h3&gt;
&lt;ul&gt;
  &lt;li&gt;深層学習モデルを複数アンサンブルしている
    &lt;ul&gt;
      &lt;li&gt;学習データに追加で外部データを用いている&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
  &lt;li&gt;Seborrheic keratosiの分類はMelanomaの分類に比べて容易な傾向だった
    &lt;ul&gt;
      &lt;li&gt;病気の性質・データの偏りから生じたものでは&lt;/li&gt;
      &lt;li&gt;一番ベストなモデルを作ったチームは追加でヒューリスティックなラベリングを追加で行っている&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
  &lt;li&gt;平均スコアがベストだったモデルは、各カテゴリ分類ではベストなモデルではなかった&lt;/li&gt;
  &lt;li&gt;一番複雑なモデルはパフォーマンスを下げており、シンプルなモデルは全体のパフォーマンスを上げている&lt;/li&gt;
  &lt;li&gt;予測の閾値は重要そう。確率的なスコア標準化(Probablistic score normalization)はsensitivityおよびspecificityのスコアをあげるために効果がありそう [&lt;a href=&quot;http://ieeexplore.ieee.org/abstract/document/8030303/&quot;&gt;Codella+&lt;/a&gt;, &lt;a href=&quot;https://www.jaad.org/article/S0190-9622(17)32202-8/fulltext&quot;&gt;Marchetti+&lt;/a&gt;]。&lt;/li&gt;
&lt;/ul&gt;

&lt;h2 id=&quot;4-どうやって有効だと検証した&quot;&gt;4. どうやって有効だと検証した？&lt;/h2&gt;

&lt;ul&gt;
  &lt;li&gt;評価尺度
    &lt;ul&gt;
      &lt;li&gt;AUC, specificity (melanoma classification)&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
&lt;/ul&gt;

&lt;h2 id=&quot;5-議論はある&quot;&gt;5. 議論はある？&lt;/h2&gt;

&lt;ul&gt;
  &lt;li&gt;Classficationタスクについて
    &lt;ul&gt;
      &lt;li&gt;モデルのアンサンブルと追加の外部データ使用が高いパフォーマンスを出すカギになる&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
&lt;/ul&gt;

&lt;h2 id=&quot;6-次に読むべき論文は&quot;&gt;6. 次に読むべき論文は？&lt;/h2&gt;

&lt;ul&gt;
  &lt;li&gt;&lt;a href=&quot;https://arxiv.org/abs/1703.03108&quot;&gt;Matsunaga, Kazuhisa, et al. “Image classification of melanoma, nevus and seborrheic keratosis by deep neural network ensemble.” arXiv preprint arXiv:1703.03108 (2017).&lt;/a&gt;&lt;/li&gt;
  &lt;li&gt;&lt;a href=&quot;https://arxiv.org/abs/1703.01976&quot;&gt;Díaz, Iván González. “Incorporating the knowledge of dermatologists to convolutional neural networks for the diagnosis of skin lesions.” arXiv preprint arXiv:1703.01976 (2017).&lt;/a&gt;&lt;/li&gt;
  &lt;li&gt;&lt;a href=&quot;https://arxiv.org/abs/1703.04819&quot;&gt;Menegola, Afonso, et al. “RECOD titans at ISIC challenge 2017.” arXiv preprint arXiv:1703.04819 (2017).&lt;/a&gt;&lt;/li&gt;
  &lt;li&gt;&lt;a href=&quot;http://ieeexplore.ieee.org/abstract/document/8030303/&quot;&gt;Codella, Noel CF, et al. “Deep learning ensembles for melanoma recognition in dermoscopy images.” IBM Journal of Research and Development 61.4 (2017): 5-1.&lt;/a&gt;&lt;/li&gt;
  &lt;li&gt;&lt;a href=&quot;https://www.jaad.org/article/S0190-9622(17)32202-8/fulltext&quot;&gt;Marchetti, Michael A., et al. “Results of the 2016 International Skin Imaging Collaboration International Symposium on Biomedical Imaging challenge: Comparison of the accuracy of computer algorithms to dermatologists for the diagnosis of melanoma from dermoscopic images.” Journal of the American Academy of Dermatology 78.2 (2018): 270-277.&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;

&lt;h2 id=&quot;論文情報リンク&quot;&gt;論文情報・リンク&lt;/h2&gt;

&lt;ul&gt;
  &lt;li&gt;&lt;a href=&quot;https://arxiv.org/abs/1710.05006&quot;&gt;Codella, Noel CF, et al. “Skin lesion analysis toward melanoma detection: A challenge at the 2017 international symposium on biomedical imaging (isbi), hosted by the international skin imaging collaboration (isic).” arXiv preprint arXiv:1710.05006 (2017).&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;</content><author><name></name></author><summary type="html">1. どんなもの？</summary></entry><entry><title type="html">RECOD Titans at ISIC Challenge 2017</title><link href="https://shunk031.github.io/paper-survey/summary/others/RECOD-Titans-at-ISIC-Challenge-2017" rel="alternate" type="text/html" title="RECOD Titans at ISIC Challenge 2017" /><published>2018-06-02T00:00:00+00:00</published><updated>2018-06-02T00:00:00+00:00</updated><id>https://shunk031.github.io/paper-survey/summary/others/RECOD-Titans-at-ISIC-Challenge-2017</id><content type="html" xml:base="https://shunk031.github.io/paper-survey/summary/others/RECOD-Titans-at-ISIC-Challenge-2017">&lt;h2 id=&quot;1-どんなもの&quot;&gt;1. どんなもの？&lt;/h2&gt;

&lt;p&gt;ISIC2017メラノーマ画像分析でSeborrheic keratosis分類タスクでベストな精度を出したモデルの解説&lt;/p&gt;

&lt;h2 id=&quot;2-先行研究と比べてどこがすごい&quot;&gt;2. 先行研究と比べてどこがすごい？&lt;/h2&gt;

&lt;ul&gt;
  &lt;li&gt;以前までの問題点
    &lt;ul&gt;
      &lt;li&gt;学習データ量が足りない&lt;/li&gt;
      &lt;li&gt;モデルの深さ&lt;/li&gt;
      &lt;li&gt;計算コスト&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;これらに対して、外部の追加データの使用・ResNet等の深いネットワークの使用・クラウドベースの計算機を使用している。&lt;/p&gt;

&lt;h2 id=&quot;3-技術や手法のキモはどこ&quot;&gt;3. 技術や手法のキモはどこ？&lt;/h2&gt;

&lt;h3 id=&quot;外部データを用いて学習データを増やす&quot;&gt;外部データを用いて学習データを増やす&lt;/h3&gt;

&lt;table&gt;
  &lt;thead&gt;
    &lt;tr&gt;
      &lt;th&gt;Dataset&lt;/th&gt;
      &lt;th style=&quot;text-align: center&quot;&gt;# of melanoma&lt;/th&gt;
      &lt;th style=&quot;text-align: center&quot;&gt;# of seborrheic keratoses&lt;/th&gt;
      &lt;th style=&quot;text-align: center&quot;&gt;# of benign nevi&lt;/th&gt;
    &lt;/tr&gt;
  &lt;/thead&gt;
  &lt;tbody&gt;
    &lt;tr&gt;
      &lt;td&gt;ISIC 2017 Challenge&lt;/td&gt;
      &lt;td style=&quot;text-align: center&quot;&gt;374&lt;/td&gt;
      &lt;td style=&quot;text-align: center&quot;&gt;254&lt;/td&gt;
      &lt;td style=&quot;text-align: center&quot;&gt;1372&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td&gt;ISIC Archive&lt;/td&gt;
      &lt;td style=&quot;text-align: center&quot;&gt;(13000 dermoscopic images)&lt;/td&gt;
      &lt;td style=&quot;text-align: center&quot;&gt;—&lt;/td&gt;
      &lt;td style=&quot;text-align: center&quot;&gt;—&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td&gt;Interactive Atlas of Dermoscopy&lt;/td&gt;
      &lt;td style=&quot;text-align: center&quot;&gt;270&lt;/td&gt;
      &lt;td style=&quot;text-align: center&quot;&gt;49&lt;/td&gt;
      &lt;td style=&quot;text-align: center&quot;&gt;—&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td&gt;Dermofit Image Library&lt;/td&gt;
      &lt;td style=&quot;text-align: center&quot;&gt;76&lt;/td&gt;
      &lt;td style=&quot;text-align: center&quot;&gt;257&lt;/td&gt;
      &lt;td style=&quot;text-align: center&quot;&gt;—&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td&gt;IRMA Skin Lesion Dataset&lt;/td&gt;
      &lt;td style=&quot;text-align: center&quot;&gt;187&lt;/td&gt;
      &lt;td style=&quot;text-align: center&quot;&gt;—&lt;/td&gt;
      &lt;td style=&quot;text-align: center&quot;&gt;—&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td&gt;PH2 Datset&lt;/td&gt;
      &lt;td style=&quot;text-align: center&quot;&gt;40&lt;/td&gt;
      &lt;td style=&quot;text-align: center&quot;&gt;—&lt;/td&gt;
      &lt;td style=&quot;text-align: center&quot;&gt;—&lt;/td&gt;
    &lt;/tr&gt;
  &lt;/tbody&gt;
&lt;/table&gt;

&lt;ul&gt;
  &lt;li&gt;すべてのデータについて、アノテーションされているラベルを考慮してマージする
    &lt;ul&gt;
      &lt;li&gt;以下のデータについては除いている
        &lt;ul&gt;
          &lt;li&gt;ISIC Archiveの診断結果がない画像&lt;/li&gt;
          &lt;li&gt;Atlasの &lt;code class=&quot;highlighter-rouge&quot;&gt;miscellaneous&lt;/code&gt; クラス&lt;/li&gt;
          &lt;li&gt;IRMAの &lt;code class=&quot;highlighter-rouge&quot;&gt;benign&lt;/code&gt; クラス&lt;/li&gt;
          &lt;li&gt;PH2の &lt;code class=&quot;highlighter-rouge&quot;&gt;atypical nevi&lt;/code&gt; クラス&lt;/li&gt;
        &lt;/ul&gt;
      &lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
  &lt;li&gt;ISIC Archiveにおいて、benignのデータの多くが15歳の患者だった
    &lt;ul&gt;
      &lt;li&gt;これらを取り除いたらスコアが微増&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
  &lt;li&gt;各データセット間で重複してるデータが存在している
    &lt;ul&gt;
      &lt;li&gt;trainとvalidationに分けるときに注意しないといけない&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
  &lt;li&gt;&lt;code class=&quot;highlighter-rouge&quot;&gt;deploy&lt;/code&gt; データ群と &lt;code class=&quot;highlighter-rouge&quot;&gt;semi&lt;/code&gt; データ群を学習用に作成
    &lt;ul&gt;
      &lt;li&gt;&lt;code class=&quot;highlighter-rouge&quot;&gt;deploy&lt;/code&gt;
        &lt;ul&gt;
          &lt;li&gt;6つのデータセットからなる9640枚の学習画像
            &lt;ul&gt;
              &lt;li&gt;keratosis分類ではこのデータ群で学習したほうがAUCスコアが良かった&lt;/li&gt;
            &lt;/ul&gt;
          &lt;/li&gt;
        &lt;/ul&gt;
      &lt;/li&gt;
      &lt;li&gt;&lt;code class=&quot;highlighter-rouge&quot;&gt;semi&lt;/code&gt;
        &lt;ul&gt;
          &lt;li&gt;3つのデータセット (ISIC2017, ISIC Archive, Interactive Atlas) からなる7544枚の学習画像
            &lt;ul&gt;
              &lt;li&gt;melanoma分類ではこのデータ群で学習したほうがAUCスコアが良かった&lt;/li&gt;
            &lt;/ul&gt;
          &lt;/li&gt;
        &lt;/ul&gt;
      &lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
&lt;/ul&gt;

&lt;h3 id=&quot;使用モデル&quot;&gt;使用モデル&lt;/h3&gt;

&lt;ul&gt;
  &lt;li&gt;ImageNetモデルのfine-tuning
    &lt;ul&gt;
      &lt;li&gt;ResNet-101&lt;/li&gt;
      &lt;li&gt;Inception-v4&lt;/li&gt;
      &lt;li&gt;~Inception-ResNet~
        &lt;ul&gt;
          &lt;li&gt;計算コストが大きいがスコアは微増しただけだったため使用を見送った&lt;/li&gt;
        &lt;/ul&gt;
      &lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
  &lt;li&gt;各クラス独立に学習を行っていたが、3クラス分類に変更した&lt;/li&gt;
&lt;/ul&gt;

&lt;h2 id=&quot;4-どうやって有効だと検証した&quot;&gt;4. どうやって有効だと検証した？&lt;/h2&gt;

&lt;ul&gt;
  &lt;li&gt;ベースラインのVGG16とResNet101やInception-v4を比べる&lt;/li&gt;
  &lt;li&gt;標準的なサイズの画像 (224x224) とより大きな高解像度の画像を入力したときの精度の比較&lt;/li&gt;
  &lt;li&gt;class-weightやsample-weightの考慮&lt;/li&gt;
  &lt;li&gt;curriculum-learningの有無
    &lt;ul&gt;
      &lt;li&gt;最初は簡単なデータで学習させ、学習が進んだら難しいデータで学習させる&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
  &lt;li&gt;最終conv層をそのままニューラルネットにするかSVMにするか&lt;/li&gt;
  &lt;li&gt;年齢や性別といった患者データを使うかどうか&lt;/li&gt;
  &lt;li&gt;用いるoptimizerの比較&lt;/li&gt;
  &lt;li&gt;異なるper-sample normalizationnの実施&lt;/li&gt;
  &lt;li&gt;アンサンブルやスタッキングの有無&lt;/li&gt;
&lt;/ul&gt;

&lt;h2 id=&quot;5-議論はある&quot;&gt;5. 議論はある？&lt;/h2&gt;
&lt;h3 id=&quot;効果がなかったこと&quot;&gt;効果がなかったこと&lt;/h3&gt;
&lt;ul&gt;
  &lt;li&gt;画像の解像度について
    &lt;ul&gt;
      &lt;li&gt;高解像度は効果なし&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
  &lt;li&gt;class-weightやsample-weightについて
    &lt;ul&gt;
      &lt;li&gt;no weighting was the best weighting&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
  &lt;li&gt;validationデータにおけるearly stoppingについて
    &lt;ul&gt;
      &lt;li&gt;特にスコアに対するインパクトはなかった&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
  &lt;li&gt;患者データの利用
    &lt;ul&gt;
      &lt;li&gt;効果があるときと無い時がある&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
  &lt;li&gt;curriculum learningの使用
    &lt;ul&gt;
      &lt;li&gt;シンプルなトレーニングのほうがよかった&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
  &lt;li&gt;セグメンテーションの情報の利用
    &lt;ul&gt;
      &lt;li&gt;今回は使えなかったけど、使うと効果が出るのではと考えられている&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
&lt;/ul&gt;

&lt;h3 id=&quot;効果があったこと&quot;&gt;効果があったこと&lt;/h3&gt;
&lt;ul&gt;
  &lt;li&gt;deepなモデルと規模の大きいデータセットを用いると効果が大きい&lt;/li&gt;
  &lt;li&gt;data augmentationは必須
    &lt;ul&gt;
      &lt;li&gt;テスト時にもdata augmentationするとよい (test time augmentation 的な)&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
  &lt;li&gt;mean subtractionは有効
    &lt;ul&gt;
      &lt;li&gt;標準偏差で割るnormalizationはスコアを悪化させた&lt;/li&gt;
      &lt;li&gt;Inception-v4では確認できた。ResNetについては不明&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
  &lt;li&gt;Stackingは有効&lt;/li&gt;
&lt;/ul&gt;

&lt;h2 id=&quot;論文情報リンク&quot;&gt;論文情報・リンク&lt;/h2&gt;

&lt;ul&gt;
  &lt;li&gt;&lt;a href=&quot;https://arxiv.org/abs/1703.04819&quot;&gt;Menegola, Afonso, et al. “RECOD titans at ISIC challenge 2017.” arXiv preprint arXiv:1703.04819 (2017).&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;</content><author><name></name></author><summary type="html">1. どんなもの？</summary></entry><entry><title type="html">Contextual Augmentation: Data Augmentation by Words with Paradigmatic Relations</title><link href="https://shunk031.github.io/paper-survey/summary/nip/Contextual-Augmentation-Data-Augmentation-by-Words-with-Paradigmatic-Relations" rel="alternate" type="text/html" title="Contextual Augmentation: Data Augmentation by Words with Paradigmatic Relations" /><published>2018-05-27T00:00:00+00:00</published><updated>2018-05-27T00:00:00+00:00</updated><id>https://shunk031.github.io/paper-survey/summary/nip/Contextual-Augmentation-Data-Augmentation-by-Words-with-Paradigmatic-Relations</id><content type="html" xml:base="https://shunk031.github.io/paper-survey/summary/nip/Contextual-Augmentation-Data-Augmentation-by-Words-with-Paradigmatic-Relations">&lt;h2 id=&quot;1-どんなもの&quot;&gt;1. どんなもの？&lt;/h2&gt;

&lt;p&gt;文脈および感情値などの条件を考慮した単語置き換えでdata augmentationを実現するContextual Augmentationを提案&lt;/p&gt;

&lt;h2 id=&quot;2-先行研究と比べてどこがすごいの&quot;&gt;2. 先行研究と比べてどこがすごいの？&lt;/h2&gt;

&lt;p&gt;ニューラルネットベースのモデルは高い精度を示すが過学習しやすい。
Data augmentationは汎化性能を向上させるテクニックであり、画像認識分野では回転やフリップなどを用いてデータのかさ増しを行っている。&lt;/p&gt;

&lt;p&gt;しかしながら自然言語処理に対するdata augmentationの適用法は限られている。
一般的にはWordNetなどを用いた単語の置き換えやルールベースの手法が用いられるが、ドメインに特化している場合も多く、一般性が失われたものとなっている。&lt;/p&gt;

&lt;p&gt;本研究ではbi-directional言語モデル(LM)を用いて、文脈を考慮した単語置き換えでdata augmentationを実現するContextual Augmentationを提案している。&lt;/p&gt;

&lt;h2 id=&quot;3-技術や手法のキモはどこにある&quot;&gt;3. 技術や手法の”キモ”はどこにある？&lt;/h2&gt;

&lt;p&gt;&lt;img src=&quot;/paper-survey/assets/img/nlp/Contextual-Augmentation-Data-Augmentation-by-Words-with-Paradigmatic-Relations/figure1.png&quot; alt=&quot;Figure 1&quot; /&gt;&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;文脈を考慮した単語予測
    &lt;ul&gt;
      &lt;li&gt;bi-directional LSTMを用いて、文脈に基づいて文中の位置 &lt;script type=&quot;math/tex&quot;&gt;i&lt;/script&gt; におけるword probabilityを計算&lt;/li&gt;
      &lt;li&gt;オンラインでdata augmentationするための単語をサンプリングする&lt;/li&gt;
      &lt;li&gt;data augmentationを制御するパラメータとしてtemperature &lt;script type=&quot;math/tex&quot;&gt;\tau&lt;/script&gt; を導入する&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
  &lt;li&gt;感情値などの条件を考慮
    &lt;ul&gt;
      &lt;li&gt;LMにおいて &lt;code class=&quot;highlighter-rouge&quot;&gt;good&lt;/code&gt; と &lt;code class=&quot;highlighter-rouge&quot;&gt;bad&lt;/code&gt; は近い表現になりやすく、反義語がdata augmentationに使われてしまう場合がある
        &lt;ul&gt;
          &lt;li&gt;label-conditional LMを用いてpositive/negativeなどのラベルを考慮し、反義語を制御する&lt;/li&gt;
        &lt;/ul&gt;
      &lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
&lt;/ul&gt;

&lt;h2 id=&quot;4-どうやって有効だと検証した&quot;&gt;4. どうやって有効だと検証した？&lt;/h2&gt;

&lt;p&gt;SST(SST2, SST5)、Subj、MPQA、RT、TRECの各データセットを用いている。モデルはLSTM、CNNをそれぞれ利用し、提案手法であるContextual Augmentationの効果を確認している。&lt;/p&gt;

&lt;h2 id=&quot;5-議論はあるか&quot;&gt;5. 議論はあるか？&lt;/h2&gt;

&lt;p&gt;&lt;img src=&quot;/paper-survey/assets/img/nlp/Contextual-Augmentation-Data-Augmentation-by-Words-with-Paradigmatic-Relations/figure2.png&quot; alt=&quot;Figure 2&quot; /&gt;&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;LMによって予測された単語は必ずしもシノニムになっていない&lt;/li&gt;
  &lt;li&gt;label-conditional LMを用いると、ラベルの性質に沿った単語の予測がなされている&lt;/li&gt;
&lt;/ul&gt;

&lt;h2 id=&quot;6-次に読むべき論文はあるか&quot;&gt;6. 次に読むべき論文はあるか？&lt;/h2&gt;

&lt;ul&gt;
  &lt;li&gt;シノニムを利用した単語置換によるdata augmentation
    &lt;ul&gt;
      &lt;li&gt;&lt;a href=&quot;http://papers.nips.cc/paper/5782-character-level-convolutional-networks-for-text-classifica&quot;&gt;Zhang, Xiang, Junbo Zhao, and Yann LeCun. “Character-level convolutional networks for text classification.” Advances in neural information processing systems. 2015.&lt;/a&gt;&lt;/li&gt;
      &lt;li&gt;&lt;a href=&quot;http://www.aclweb.org/anthology/D15-1306&quot;&gt;Wang, William Yang, and Diyi Yang. “That’s So Annoying!!!: A Lexical and Frame-Semantic Embedding Based Data Augmentation Approach to Automatic Categorization of Annoying Behaviors using# petpeeve Tweets.” Proceedings of the 2015 Conference on Empirical Methods in Natural Language Processing. 2015.&lt;/a&gt;&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
  &lt;li&gt;文法推論 (grammar induction)を用いたdata augmentation
    &lt;ul&gt;
      &lt;li&gt;&lt;a href=&quot;https://arxiv.org/abs/1606.03622&quot;&gt;Jia, Robin, and Percy Liang. “Data recombination for neural semantic parsing.” arXiv preprint arXiv:1606.03622 (2016).&lt;/a&gt;&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
  &lt;li&gt;タスク固有のヒューリスティックを利用したdata augmentation
    &lt;ul&gt;
      &lt;li&gt;&lt;a href=&quot;https://dl.acm.org/citation.cfm?id=1609091&quot;&gt;Fürstenau, Hagen, and Mirella Lapata. “Semi-supervised semantic role labeling.” Proceedings of the 12th Conference of the European Chapter of the Association for Computational Linguistics. Association for Computational Linguistics, 2009.&lt;/a&gt;&lt;/li&gt;
      &lt;li&gt;&lt;a href=&quot;http://www.aclweb.org/anthology/W17-3529&quot;&gt;Kafle, Kushal, Mohammed Yousefhussien, and Christopher Kanan. “Data augmentation for visual question answering.” Proceedings of the 10th International Conference on Natural Language Generation. 2017.&lt;/a&gt;&lt;/li&gt;
      &lt;li&gt;&lt;a href=&quot;http://www.aclweb.org/anthology/K17-2010&quot;&gt;Silfverberg, Miikka, et al. “Data Augmentation for Morphological Reinflection.” Proceedings of the CoNLL SIGMORPHON 2017 Shared Task: Universal Morphological Reinflection (2017): 90-99.&lt;/a&gt;&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
  &lt;li&gt;Autoencoderを用いたdata augmentation
    &lt;ul&gt;
      &lt;li&gt;&lt;a href=&quot;http://www.aclweb.org/anthology/K17-2002&quot;&gt;Bergmanis, Toms, et al. “Training Data Augmentation for Low-Resource Morphological Inflection.” Proceedings of the CoNLL SIGMORPHON 2017 Shared Task: Universal Morphological Reinflection (2017): 31-39.&lt;/a&gt;&lt;/li&gt;
      &lt;li&gt;&lt;a href=&quot;http://www.aaai.org/ocs/index.php/AAAI/AAAI17/paper/download/14299/14261&quot;&gt;Xu, Weidi, et al. “Variational Autoencoder for Semi-Supervised Text Classification.” AAAI. 2017.&lt;/a&gt;&lt;/li&gt;
      &lt;li&gt;&lt;a href=&quot;http://proceedings.mlr.press/v70/hu17e.html&quot;&gt;Hu, Zhiting, et al. “Toward controlled generation of text.” International Conference on Machine Learning. 2017.&lt;/a&gt;&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
  &lt;li&gt;Encoder-Decoderを用いたdata augmentation
    &lt;ul&gt;
      &lt;li&gt;&lt;a href=&quot;https://arxiv.org/abs/1606.07947&quot;&gt;Kim, Yoon, and Alexander M. Rush. “Sequence-level knowledge distillation.” arXiv preprint arXiv:1606.07947 (2016).&lt;/a&gt;&lt;/li&gt;
      &lt;li&gt;&lt;a href=&quot;https://arxiv.org/abs/1511.06709&quot;&gt;Sennrich, Rico, Barry Haddow, and Alexandra Birch. “Improving neural machine translation models with monolingual data.” arXiv preprint arXiv:1511.06709 (2015).&lt;/a&gt;&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
  &lt;li&gt;本研究に一番近い立ち位置の先行研究
    &lt;ul&gt;
      &lt;li&gt;&lt;a href=&quot;https://dl.acm.org/citation.cfm?id=2002793&quot;&gt;Kolomiyets, Oleksandr, Steven Bethard, and Marie-Francine Moens. “Model-portability experiments for textual temporal analysis.” Proceedings of the 49th Annual Meeting of the Association for Computational Linguistics: Human Language Technologies: short papers-Volume 2. Association for Computational Linguistics, 2011.&lt;/a&gt;&lt;/li&gt;
      &lt;li&gt;&lt;a href=&quot;https://arxiv.org/abs/1705.00440&quot;&gt;Fadaee, Marzieh, Arianna Bisazza, and Christof Monz. “Data augmentation for low-resource neural machine translation.” arXiv preprint arXiv:1705.00440 (2017).&lt;/a&gt;&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
&lt;/ul&gt;

&lt;h3 id=&quot;論文情報リンク&quot;&gt;論文情報・リンク&lt;/h3&gt;

&lt;ul&gt;
  &lt;li&gt;&lt;a href=&quot;https://arxiv.org/abs/1805.06201&quot;&gt;Kobayashi, Sosuke. “Contextual Augmentation: Data Augmentation by Words with Paradigmatic Relations.” arXiv preprint arXiv:1805.06201 (2018).&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;</content><author><name></name></author><summary type="html">1. どんなもの？</summary></entry><entry><title type="html">Hierarchical Attention Networks for Document Classification</title><link href="https://shunk031.github.io/paper-survey/summary/nlp/Hierarchical-Attention-Networks-for-Document-Classification" rel="alternate" type="text/html" title="Hierarchical Attention Networks for Document Classification" /><published>2018-05-06T00:00:00+00:00</published><updated>2018-05-06T00:00:00+00:00</updated><id>https://shunk031.github.io/paper-survey/summary/nlp/Hierarchical-Attention-Networks-for-Document-Classification</id><content type="html" xml:base="https://shunk031.github.io/paper-survey/summary/nlp/Hierarchical-Attention-Networks-for-Document-Classification">&lt;h2 id=&quot;1-どんなもの&quot;&gt;1. どんなもの？&lt;/h2&gt;

&lt;p&gt;Attentionを用いてより重要な単語・文に注目させ、同時に文書の階層的構造を捉えることができるHierarchal Attention Network (HAN) を提案&lt;/p&gt;

&lt;h2 id=&quot;2-先行研究と比べてどこがすごいの&quot;&gt;2. 先行研究と比べてどこがすごいの？&lt;/h2&gt;

&lt;p&gt;一般的にテキスト分類をする場合、全ての単語が文書の意味を捉えるのに重要であるとは限らない。&lt;/p&gt;

&lt;p&gt;本研究では単語レベル、文レベルでAttentionを適用することにより重要な単語および文を抽出し、
同時に文書の階層的な構造を捉えることができるHierarchal Attention Network (HAN) を提案している。&lt;/p&gt;

&lt;h2 id=&quot;3-技術や手法のキモはどこにある&quot;&gt;3. 技術や手法の”キモ”はどこにある？&lt;/h2&gt;

&lt;p&gt;&lt;img src=&quot;/paper-survey/assets/img/nlp/Hierarchical-Attention-Networks-for-Document-Classification/figure2.png&quot; alt=&quot;Figure 2&quot; /&gt;&lt;/p&gt;

&lt;p&gt;GRUによってエンコードされたembeddingに対して、単語レベル、文レベルの2つのレベルでAttentionを適用する。&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;Hierarchal Attention Network (HAN)
    &lt;ul&gt;
      &lt;li&gt;GRU-based sequence encoder
        &lt;ul&gt;
          &lt;li&gt;Word Encoder&lt;/li&gt;
          &lt;li&gt;Sentence Attention&lt;/li&gt;
        &lt;/ul&gt;
      &lt;/li&gt;
      &lt;li&gt;Hierarchal Attention
        &lt;ul&gt;
          &lt;li&gt;Word Attention&lt;/li&gt;
          &lt;li&gt;Sentence Encoder&lt;/li&gt;
        &lt;/ul&gt;
      &lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;Attentionの計算はエンコードされたベクトルに対して1層のMLPを用いて隠れ層ベクトルの重要度を算出する。&lt;/p&gt;

&lt;h2 id=&quot;4-どうやって有効だと検証した&quot;&gt;4. どうやって有効だと検証した？&lt;/h2&gt;

&lt;p&gt;複数のデータセットと複数のベースラインを用いて提案手法であるHANの性能を評価している。
Attentionの効果を見るため、Hierarchal Network(HN)にaverage-poolingを使うHN-AVE、およびmax-poolingを使うHN-MAX、そして提案手法であるHNにAttentionを組み込んだHN-ATTの性能についても比較している。&lt;/p&gt;

&lt;h3 id=&quot;データセットについて&quot;&gt;データセットについて&lt;/h3&gt;

&lt;table&gt;
  &lt;thead&gt;
    &lt;tr&gt;
      &lt;th&gt;Data set&lt;/th&gt;
      &lt;th&gt;# of classes&lt;/th&gt;
      &lt;th&gt;# of documents&lt;/th&gt;
      &lt;th&gt;Author&lt;/th&gt;
    &lt;/tr&gt;
  &lt;/thead&gt;
  &lt;tbody&gt;
    &lt;tr&gt;
      &lt;td&gt;Yelp 2013&lt;/td&gt;
      &lt;td&gt;5&lt;/td&gt;
      &lt;td&gt;335,018&lt;/td&gt;
      &lt;td&gt;&lt;a href=&quot;http://www.aclweb.org/anthology/D15-1167&quot;&gt;Tang et al., 2015&lt;/a&gt;&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td&gt;Yelp 2014&lt;/td&gt;
      &lt;td&gt;5&lt;/td&gt;
      &lt;td&gt;1,125,457&lt;/td&gt;
      &lt;td&gt;&lt;a href=&quot;http://www.aclweb.org/anthology/D15-1167&quot;&gt;Tang et al., 2015&lt;/a&gt;&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td&gt;Yelp 2015&lt;/td&gt;
      &lt;td&gt;5&lt;/td&gt;
      &lt;td&gt;1,569,264&lt;/td&gt;
      &lt;td&gt;&lt;a href=&quot;http://www.aclweb.org/anthology/D15-1167&quot;&gt;Tang et al., 2015&lt;/a&gt;&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td&gt;IMDB review&lt;/td&gt;
      &lt;td&gt;10&lt;/td&gt;
      &lt;td&gt;348,415&lt;/td&gt;
      &lt;td&gt;&lt;a href=&quot;https://dl.acm.org/citation.cfm?id=2623758&quot;&gt;Diao et al., 2014&lt;/a&gt;&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td&gt;Yahoo Answer&lt;/td&gt;
      &lt;td&gt;10&lt;/td&gt;
      &lt;td&gt;1,450,000&lt;/td&gt;
      &lt;td&gt;&lt;a href=&quot;https://arxiv.org/abs/1509.01626&quot;&gt;Zhang et al., 2015&lt;/a&gt;&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td&gt;Amazon review&lt;/td&gt;
      &lt;td&gt;5&lt;/td&gt;
      &lt;td&gt;3,650,000&lt;/td&gt;
      &lt;td&gt;&lt;a href=&quot;https://arxiv.org/abs/1509.01626&quot;&gt;Zhang et al., 2015&lt;/a&gt;&lt;/td&gt;
    &lt;/tr&gt;
  &lt;/tbody&gt;
&lt;/table&gt;

&lt;h3 id=&quot;ベースラインについて&quot;&gt;ベースラインについて&lt;/h3&gt;

&lt;ul&gt;
  &lt;li&gt;Linear methods
    &lt;ul&gt;
      &lt;li&gt;BoW and BoW + TFIDF&lt;/li&gt;
      &lt;li&gt;n-grams and n-grams + TFIDF&lt;/li&gt;
      &lt;li&gt;Bag-of-means&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
  &lt;li&gt;SVMs
    &lt;ul&gt;
      &lt;li&gt;Text Features&lt;/li&gt;
      &lt;li&gt;Average SG&lt;/li&gt;
      &lt;li&gt;SSWE&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
  &lt;li&gt;Neural Network methods
    &lt;ul&gt;
      &lt;li&gt;CNN-word&lt;/li&gt;
      &lt;li&gt;CNN_char&lt;/li&gt;
      &lt;li&gt;LSTM&lt;/li&gt;
      &lt;li&gt;Conv-GRNN&lt;/li&gt;
      &lt;li&gt;LSTM-GRNN&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
  &lt;li&gt;Hierarchal Network
    &lt;ul&gt;
      &lt;li&gt;HN-AVE&lt;/li&gt;
      &lt;li&gt;HN-MAX&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
&lt;/ul&gt;

&lt;h2 id=&quot;5-議論はあるか&quot;&gt;5. 議論はあるか？&lt;/h2&gt;

&lt;p&gt;&lt;img src=&quot;/paper-survey/assets/img/nlp/Hierarchical-Attention-Networks-for-Document-Classification/figure5.png&quot; alt=&quot;Figure 5&quot; /&gt;&lt;/p&gt;

&lt;p&gt;Figure 5の最初の文書でホタテを気に入らないような文章がある場合、単文だけを見ると、これは否定的なコメントだと感じられる。
しかし、提案手法ではこの文章の文脈を見て、これが肯定的な評価であり、この文を無視することを選択していることが示されている。&lt;/p&gt;

&lt;h2 id=&quot;6-次に読むべき論文はあるか&quot;&gt;6. 次に読むべき論文はあるか？&lt;/h2&gt;

&lt;ul&gt;
  &lt;li&gt;Attentionについて
    &lt;ul&gt;
      &lt;li&gt;&lt;a href=&quot;https://arxiv.org/abs/1409.0473&quot;&gt;Bahdanau, Dzmitry, Kyunghyun Cho, and Yoshua Bengio. “Neural machine translation by jointly learning to align and translate.” arXiv preprint arXiv:1409.0473 (2014).&lt;/a&gt;&lt;/li&gt;
      &lt;li&gt;&lt;a href=&quot;http://www.jmlr.org/proceedings/papers/v37/xuc15.pdf&quot;&gt;Xu, Kelvin, et al. “Show, attend and tell: Neural image caption generation with visual attention.” International Conference on Machine Learning. 2015.&lt;/a&gt;&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
&lt;/ul&gt;

&lt;h3 id=&quot;論文情報リンク&quot;&gt;論文情報・リンク&lt;/h3&gt;

&lt;ul&gt;
  &lt;li&gt;&lt;a href=&quot;http://www.aclweb.org/anthology/N16-1174&quot;&gt;Yang, Zichao, et al. “Hierarchical attention networks for document classification.” Proceedings of the 2016 Conference of the North American Chapter of the Association for Computational Linguistics: Human Language Technologies. 2016.&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;</content><author><name></name></author><summary type="html">1. どんなもの？</summary></entry><entry><title type="html">Utilizing Visual Forms of Japanese Characters for Neural Review Classification</title><link href="https://shunk031.github.io/paper-survey/summary/nlp/Utilizing-Visual-Forms-of-Japanese-Characters-for-Neural-Review-Classification" rel="alternate" type="text/html" title="Utilizing Visual Forms of Japanese Characters for Neural Review Classification" /><published>2018-04-30T00:00:00+00:00</published><updated>2018-04-30T00:00:00+00:00</updated><id>https://shunk031.github.io/paper-survey/summary/nlp/Utilizing-Visual-Forms-of-Japanese-Characters-for-Neural-Review-Classification</id><content type="html" xml:base="https://shunk031.github.io/paper-survey/summary/nlp/Utilizing-Visual-Forms-of-Japanese-Characters-for-Neural-Review-Classification">&lt;h2 id=&quot;1-どんなもの&quot;&gt;1. どんなもの？&lt;/h2&gt;

&lt;p&gt;文字の見た目を考慮した文字embeddingを用いて日本語の評判分析を行う&lt;/p&gt;

&lt;h2 id=&quot;2-先行研究と比べてどこがすごいの&quot;&gt;2. 先行研究と比べてどこがすごいの？&lt;/h2&gt;

&lt;p&gt;日本語や中国語の文字は表意文字であり、文字自身が意味を持っている。通常の自然言語処理の手法では、文字の見た目の情報は無視し、文字IDの羅列として扱う。
本研究では表意文字や記号の形状を考慮した日本語の評判分析を行うモデルを提案している。&lt;/p&gt;

&lt;h2 id=&quot;3-技術や手法のキモはどこにある&quot;&gt;3. 技術や手法の”キモ”はどこにある？&lt;/h2&gt;

&lt;p&gt;&lt;img src=&quot;/paper-survey/assets/img/nlp/Utilizing-Visual-Forms-of-Japanese-Characters-for-Neural-Review-Classification/figure2.png&quot; alt=&quot;Figure 2&quot; /&gt;&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;Character-based Hierarchal Attention Networks (HAN) をベースとしたモデル
    &lt;ul&gt;
      &lt;li&gt;HANと比べて文字embeddingのパラメータ数が大幅に減少している&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
  &lt;li&gt;文字を文字画像に変換し、そこからConvolutional Neural Networks (CNN) を通して文字の形状情報を捉えた文字embeddingを取り出す&lt;/li&gt;
&lt;/ul&gt;

&lt;h2 id=&quot;4-どうやって有効だと検証した&quot;&gt;4. どうやって有効だと検証した？&lt;/h2&gt;

&lt;p&gt;6段階の評価と7カテゴリが付与されている&lt;a href=&quot;https://www.nii.ac.jp/dsc/idr/en/rakuten/rakuten.html&quot;&gt;Raluten Travel review&lt;/a&gt;を用いて提案手法の性能を評価している。
ベースラインとして先行研究のHANを利用し、前処理として&lt;a href=&quot;https://github.com/ikegami-yukino/neologdn&quot;&gt;neologdn&lt;/a&gt;を用いてNFKCのユニコード標準化を行っている。&lt;/p&gt;

&lt;h2 id=&quot;5-議論はあるか&quot;&gt;5. 議論はあるか？&lt;/h2&gt;

&lt;ul&gt;
  &lt;li&gt;Visual attentionを適用して評判分析の際に文字のどの部分に着目しているのか可視化したい&lt;/li&gt;
  &lt;li&gt;従来の部首の辞書を用いた特徴を利用すれば未知の文字に対しても有効に特徴を取得できるのではないだろうか&lt;/li&gt;
&lt;/ul&gt;

&lt;h2 id=&quot;6-次に読むべき論文はあるか&quot;&gt;6. 次に読むべき論文はあるか？&lt;/h2&gt;

&lt;ul&gt;
  &lt;li&gt;HANについて
    &lt;ul&gt;
      &lt;li&gt;&lt;a href=&quot;http://www.aclweb.org/anthology/N16-1174&quot;&gt;Yang, Zichao, et al. “Hierarchical attention networks for document classification.” Proceedings of the 2016 Conference of the North American Chapter of the Association for Computational Linguistics: Human Language Technologies. 2016.&lt;/a&gt;&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
&lt;/ul&gt;

&lt;h3 id=&quot;論文情報リンク&quot;&gt;論文情報・リンク&lt;/h3&gt;

&lt;ul&gt;
  &lt;li&gt;&lt;a href=&quot;http://www.aclweb.org/anthology/I17-2064&quot;&gt;Toyama, Yota, Makoto Miwa, and Yutaka Sasaki. “Utilizing Visual Forms of Japanese Characters for Neural Review Classification.” Proceedings of the Eighth International Joint Conference on Natural Language Processing (Volume 2: Short Papers). Vol. 2. 2017.&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;</content><author><name></name></author><summary type="html">1. どんなもの？</summary></entry><entry><title type="html">Realistic Evaluation of Semi-Supervised Learning Algorithms</title><link href="https://shunk031.github.io/paper-survey/summary/cv/Realistic-Evaluation-of-Semi-Supervised-Learning-Algorithms" rel="alternate" type="text/html" title="Realistic Evaluation of Semi-Supervised Learning Algorithms" /><published>2018-04-28T00:00:00+00:00</published><updated>2018-04-28T00:00:00+00:00</updated><id>https://shunk031.github.io/paper-survey/summary/cv/Realistic-Evaluation-of-Semi-Supervised-Learning-Algorithms</id><content type="html" xml:base="https://shunk031.github.io/paper-survey/summary/cv/Realistic-Evaluation-of-Semi-Supervised-Learning-Algorithms">&lt;h2 id=&quot;1-どんなもの&quot;&gt;1. どんなもの？&lt;/h2&gt;

&lt;p&gt;現在SoTAである半教師あり学習のアルゴリズムについて、平等なテスト環境で性能を比較した。&lt;/p&gt;

&lt;h2 id=&quot;2-先行研究と比べてどこがすごいの&quot;&gt;2. 先行研究と比べてどこがすごいの？&lt;/h2&gt;

&lt;p&gt;Deep neural networkを学習させるためには大量の教師データが必要になるが、実際はデータが取りづらかったり、コストがかかる。
そこで教師ラベルのないデータセットも有効に活用する、半教師あり学習(SSL)が提案されている。&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;/paper-survey/assets/img/cv/Realistic-Evaluation-of-Semi-Supervised-Learning-Algorithms/figure1.png&quot; alt=&quot;Figure 1&quot; /&gt;&lt;/p&gt;

&lt;p&gt;先行研究で成果を上げているモデルは実際の使用環境を想定したモデルになっているかが疑問点としてあげられている。
本研究では現在デファクトスタンダートである半教師あり学習アルゴリズムに対して、それぞれ現実世界を想定した平等なテスト環境で性能を比較している。&lt;/p&gt;

&lt;h2 id=&quot;3-技術や手法のキモはどこにある&quot;&gt;3. 技術や手法の”キモ”はどこにある？&lt;/h2&gt;

&lt;p&gt;従来の半教師あり学習の評価方法を見直し、現実世界での適用を想定した以下の評価方法を用いて先行研究のモデルを評価した。&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;Shared Implementation
    &lt;ul&gt;
      &lt;li&gt;パラメータの初期化方法やデータの前処理、augmentation、正則化等を標準化する&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
  &lt;li&gt;High-Quality Supervised Baseline
    &lt;ul&gt;
      &lt;li&gt;SSLのゴールは &lt;script type=&quot;math/tex&quot;&gt;\mathcal{D}&lt;/script&gt; と &lt;script type=&quot;math/tex&quot;&gt;\mathcal{D}_{UL}&lt;/script&gt; を用いて学習させたモデルが、 &lt;script type=&quot;math/tex&quot;&gt;\mathcal{D}&lt;/script&gt; のみを用いて学習したモデルより良い精度を出すことである&lt;/li&gt;
      &lt;li&gt;そこで比較対象であるベースラインのモデルは &lt;script type=&quot;math/tex&quot;&gt;\mathcal{D}&lt;/script&gt; のみを用いて学習させるべき&lt;/li&gt;
      &lt;li&gt;ベースラインのモデルのパラメータ探索もSSLモデルと同様の回数探索するように設定&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
  &lt;li&gt;Comparison to Transfer Learning
    &lt;ul&gt;
      &lt;li&gt;学習済みモデルをfine-tuningした結果はあまり報告されないので、本研究ではベースラインとして精度を報告する&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
  &lt;li&gt;Consider Class Distribution Mismatch
    &lt;ul&gt;
      &lt;li&gt;ラベル付きデータとラベルなしデータの分布の違いによる影響について報告する&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
  &lt;li&gt;Varying the Amount of Labeled and Unlabeled Data
    &lt;ul&gt;
      &lt;li&gt;ラベルなしデータは巨大である(インターネット上から取得)場合か、医療画像のようにデータの規模が小さい場合が考えられる&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
  &lt;li&gt;Realistically Small Validation Set
    &lt;ul&gt;
      &lt;li&gt;先行研究ではtrainingセットの中から一部ラベルを落としたデータを用いて学習させ、validationセットでモデルのチューニングをしていた。このときラベル有りデータの数はvalidationセットのほうが遥かに多い&lt;/li&gt;
      &lt;li&gt;現実世界ではラベルを多く含むデータセットで学習を行うため、先行研究の評価方法では実践的な評価ができていないため、本研究ではtrainingセットより小さいvalidationセットを用いてパラメータをチューニングする&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
&lt;/ul&gt;

&lt;h2 id=&quot;4-どうやって有効だと検証した&quot;&gt;4. どうやって有効だと検証した？&lt;/h2&gt;

&lt;h3 id=&quot;使用したsslアルゴリズムについて&quot;&gt;使用したSSLアルゴリズムについて&lt;/h3&gt;

&lt;table&gt;
  &lt;thead&gt;
    &lt;tr&gt;
      &lt;th&gt;Method&lt;/th&gt;
      &lt;th&gt;Type&lt;/th&gt;
      &lt;th&gt;Author&lt;/th&gt;
    &lt;/tr&gt;
  &lt;/thead&gt;
  &lt;tbody&gt;
    &lt;tr&gt;
      &lt;td&gt;Stochastic Perturbations&lt;/td&gt;
      &lt;td&gt;Consistency Regularization&lt;/td&gt;
      &lt;td&gt;&lt;a href=&quot;http://papers.nips.cc/paper/6332-regularization-with-stochastic-transformations-and-perturbations-for-deep-semi-supervised-learning&quot;&gt;Sajjadi et al., 2016&lt;/a&gt;&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td&gt;Ⅱ-Model&lt;/td&gt;
      &lt;td&gt;Consistency Regularization&lt;/td&gt;
      &lt;td&gt;&lt;a href=&quot;https://arxiv.org/abs/1610.02242&quot;&gt;Laine &amp;amp; Aila, 2017&lt;/a&gt;&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td&gt;Temporal Embsembling&lt;/td&gt;
      &lt;td&gt;Consistency Regularization&lt;/td&gt;
      &lt;td&gt;&lt;a href=&quot;https://arxiv.org/abs/1610.02242&quot;&gt;Laine &amp;amp; Aila, 2017&lt;/a&gt;&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td&gt;Mean Teacher&lt;/td&gt;
      &lt;td&gt;Consistency Regularization&lt;/td&gt;
      &lt;td&gt;&lt;a href=&quot;http://papers.nips.cc/paper/6719-mean-teachers-are-better-role-models-weight-averaged-consistency-targets-improve-semi-supervised-deep-learning-results&quot;&gt;Tarvainen &amp;amp; Valpola, 2017&lt;/a&gt;&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td&gt;Virtual Adversarial Training&lt;/td&gt;
      &lt;td&gt;Consistency Regularization&lt;/td&gt;
      &lt;td&gt;&lt;a href=&quot;https://arxiv.org/abs/1704.03976&quot;&gt;Miyato et al., 2017&lt;/a&gt;&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td&gt;Entropy-Based&lt;/td&gt;
      &lt;td&gt;Entropy-Based&lt;/td&gt;
      &lt;td&gt;&lt;a href=&quot;http://papers.nips.cc/paper/2740-semi-supervised-learning-by-entropy-minimization.pdf&quot;&gt;Grandvalet &amp;amp; Bengio, 2005&lt;/a&gt;&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td&gt;Pseudo-Labeling&lt;/td&gt;
      &lt;td&gt;Pseudo-Labeling&lt;/td&gt;
      &lt;td&gt;&lt;a href=&quot;https://www.kaggle.com/blobs/download/forum-message-attachment-files/746/pseudo_label_final.pdf&quot;&gt;Lee, 2013&lt;/a&gt;&lt;/td&gt;
    &lt;/tr&gt;
  &lt;/tbody&gt;
&lt;/table&gt;

&lt;h3 id=&quot;評価方法について&quot;&gt;評価方法について&lt;/h3&gt;

&lt;ul&gt;
  &lt;li&gt;Reproduction
    &lt;ul&gt;
      &lt;li&gt;ベースモデルにWide ResNet (WRN-28-2) を使用&lt;/li&gt;
      &lt;li&gt;Google Cloud Machine Learning’s hyperparameter tuning serviceを用いてGaussian Process-based black box optimizationを行った&lt;/li&gt;
      &lt;li&gt;評価用データセットとしてSVHNとCIFAR-10を使用&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
  &lt;li&gt;Fully-Supervised Baselines&lt;/li&gt;
  &lt;li&gt;Transfer Learning&lt;/li&gt;
  &lt;li&gt;Class Distribution Mismatch&lt;/li&gt;
  &lt;li&gt;Varying Data Amounts&lt;/li&gt;
  &lt;li&gt;Small Validation Sets&lt;/li&gt;
&lt;/ul&gt;

&lt;h2 id=&quot;5-議論はあるか&quot;&gt;5. 議論はあるか？&lt;/h2&gt;

&lt;ul&gt;
  &lt;li&gt;SSLの各アルゴリズムに対して分布が違うラベルなしデータを学習に使うと学習が上手く進まなかった&lt;/li&gt;
  &lt;li&gt;ラベルありデータと同様の分布からサンプリングされるラベルなしデータを使用すべきである&lt;/li&gt;
&lt;/ul&gt;

&lt;h2 id=&quot;6-次に読むべき論文はあるか&quot;&gt;6. 次に読むべき論文はあるか？&lt;/h2&gt;

&lt;ul&gt;
  &lt;li&gt;Stochastic Perturbationsについて
    &lt;ul&gt;
      &lt;li&gt;&lt;a href=&quot;http://papers.nips.cc/paper/6332-regularization-with-stochastic-transformations-and-perturbations-for-deep-semi-supervised-learning&quot;&gt;Sajjadi, Mehdi, Mehran Javanmardi, and Tolga Tasdizen. “Regularization with stochastic transformations and perturbations for deep semi-supervised learning.” Advances in Neural Information Processing Systems. 2016.&lt;/a&gt;&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
  &lt;li&gt;Ⅱ-Model / Temporal Ensemblingについて
    &lt;ul&gt;
      &lt;li&gt;&lt;a href=&quot;https://arxiv.org/abs/1610.02242&quot;&gt;Laine, Samuli, and Timo Aila. “Temporal ensembling for semi-supervised learning.” arXiv preprint arXiv:1610.02242 (2016).&lt;/a&gt;&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
  &lt;li&gt;Mean Teacherについて
    &lt;ul&gt;
      &lt;li&gt;&lt;a href=&quot;http://papers.nips.cc/paper/6719-mean-teachers-are-better-role-models-weight-averaged-consistency-targets-improve-semi-supervised-deep-learning-results&quot;&gt;Tarvainen, Antti, and Harri Valpola. “Mean teachers are better role models: Weight-averaged consistency targets improve semi-supervised deep learning results.” Advances in neural information processing systems. 2017.&lt;/a&gt;&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
  &lt;li&gt;Virtual Adversarial Trainingについて
    &lt;ul&gt;
      &lt;li&gt;&lt;a href=&quot;https://arxiv.org/abs/1704.03976&quot;&gt;Miyato, Takeru, et al. “Virtual adversarial training: a regularization method for supervised and semi-supervised learning.” arXiv preprint arXiv:1704.03976 (2017).&lt;/a&gt;&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
  &lt;li&gt;Entropy-basedな手法について
    &lt;ul&gt;
      &lt;li&gt;&lt;a href=&quot;http://papers.nips.cc/paper/2740-semi-supervised-learning-by-entropy-minimization.pdf&quot;&gt;Grandvalet, Yves, and Yoshua Bengio. “Semi-supervised learning by entropy minimization.” Advances in neural information processing systems. 2005.&lt;/a&gt;&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
  &lt;li&gt;Pseudo-Labelingについて
    &lt;ul&gt;
      &lt;li&gt;&lt;a href=&quot;https://www.kaggle.com/blobs/download/forum-message-attachment-files/746/pseudo_label_final.pdf&quot;&gt;Lee, Dong-Hyun. “Pseudo-label: The simple and efficient semi-supervised learning method for deep neural networks.” Workshop on Challenges in Representation Learning, ICML. Vol. 3. 2013.&lt;/a&gt;&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
&lt;/ul&gt;

&lt;h3 id=&quot;論文情報リンク&quot;&gt;論文情報・リンク&lt;/h3&gt;

&lt;ul&gt;
  &lt;li&gt;&lt;a href=&quot;https://arxiv.org/abs/1804.09170&quot;&gt;Oliver, Avital, et al. “Realistic Evaluation of Semi-Supervised Learning Algorithms.” arXiv preprint arXiv:1804.09170 (2018).&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;</content><author><name></name></author><summary type="html">1. どんなもの？</summary></entry><entry><title type="html">Word Embedding Perturbation for Sentence Classification</title><link href="https://shunk031.github.io/paper-survey/summary/nlp/Word-Embedding-Perturbation-for-Sentence-Classification" rel="alternate" type="text/html" title="Word Embedding Perturbation for Sentence Classification" /><published>2018-04-27T00:00:00+00:00</published><updated>2018-04-27T00:00:00+00:00</updated><id>https://shunk031.github.io/paper-survey/summary/nlp/Word-Embedding-Perturbation-for-Sentence-Classification</id><content type="html" xml:base="https://shunk031.github.io/paper-survey/summary/nlp/Word-Embedding-Perturbation-for-Sentence-Classification">&lt;h2 id=&quot;1-どんなもの&quot;&gt;1. どんなもの？&lt;/h2&gt;

&lt;p&gt;入力される単語embeddingに対していくつかのノイズで摂動を与え、文書分類における精度の検証する&lt;/p&gt;

&lt;h2 id=&quot;2-先行研究と比べてどこがすごいの&quot;&gt;2. 先行研究と比べてどこがすごいの？&lt;/h2&gt;

&lt;p&gt;自然言語処理では単語は離散的であり、連続空間では単語表現を変更できないため、一般的にdata augmentationは利用されてこなかった。&lt;/p&gt;

&lt;p&gt;近年ではシソーラスを用いた単語の置換や、2つの単語間の依存関係の向きを逆にすることで学習データを2倍に増やす手法が提案されている。これらは外部の知識体系が必要であったり、洗練されたNLPツールが必要である。&lt;/p&gt;

&lt;p&gt;またBag-of-Wordsに対してランダムにdropoutさせる手法を用いて、文書分類で性能を向上させたものがある。しかしながらノイズの与え方を比較していなかったり、単語の分散表現空間に対して適用していない問題がある。&lt;/p&gt;

&lt;p&gt;本研究では連続空間上の単語embeddingに対して複数種類のノイズで摂動を与え、文書分類における精度の検証を行っている。&lt;/p&gt;

&lt;h2 id=&quot;3-技術や手法のキモはどこにある&quot;&gt;3. 技術や手法の”キモ”はどこにある？&lt;/h2&gt;

&lt;p&gt;Word embeddingレイヤーに対して &lt;code class=&quot;highlighter-rouge&quot;&gt;word embedding perturbation&lt;/code&gt; を適用。&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;Gaussian Noise
    &lt;ul&gt;
      &lt;li&gt;入力される単語embeddingに対して、ガウスノイズ &lt;script type=&quot;math/tex&quot;&gt;e&lt;/script&gt; を適用する&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
&lt;/ul&gt;

&lt;script type=&quot;math/tex; mode=display&quot;&gt;X_{emb} \leftarrow X_{emb} \odot e, e \sim \mathcal{N}(I, \sigma^{2}I)&lt;/script&gt;

&lt;ul&gt;
  &lt;li&gt;Bernoulli Noise Augmentation
    &lt;ul&gt;
      &lt;li&gt;先行研究で提案されているDropoutを参考に、確率 &lt;script type=&quot;math/tex&quot;&gt;p&lt;/script&gt; で単語embeddingを0にする&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
&lt;/ul&gt;

&lt;script type=&quot;math/tex; mode=display&quot;&gt;X_{emb} \leftarrow \frac{1}{p} X_{emb} \odot e, e \sim \mathcal{B}(n, p)&lt;/script&gt;

&lt;ul&gt;
  &lt;li&gt;Adversarial Training
    &lt;ul&gt;
      &lt;li&gt;loss関数が最大になるような方向にノイズを加える&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
&lt;/ul&gt;

&lt;script type=&quot;math/tex; mode=display&quot;&gt;e \leftarrow e + \sigma \frac{g}{||g||}, g = \nabla_{e} L(X:\theta)&lt;/script&gt;

&lt;p&gt;文書の意味を考慮したrandom perturbationについて。&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;Word Dropout
    &lt;ul&gt;
      &lt;li&gt;ベルヌーイ分布に従ってランダムに単語 &lt;script type=&quot;math/tex&quot;&gt;X&lt;/script&gt; をdropoutさせる&lt;/li&gt;
      &lt;li&gt;dropoutさせた単語は &lt;code class=&quot;highlighter-rouge&quot;&gt;UNK&lt;/code&gt; と同じ表現にする&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
&lt;/ul&gt;

&lt;script type=&quot;math/tex; mode=display&quot;&gt;X \leftarrow X \odot \overrightarrow{e}, \overrightarrow{e} \sim \mathcal{B}(n, p)&lt;/script&gt;

&lt;ul&gt;
  &lt;li&gt;Semantic Dropout
    &lt;ul&gt;
      &lt;li&gt;単語embeddingの各次元はそれぞれセマンティックな意味を持っていると考えられる&lt;/li&gt;
      &lt;li&gt;単語間の共起を覚えさせるのではなく意味的な特徴を捉えてほしいため、単語embeddingの各次元をランダムにdropoutさせる&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
  &lt;li&gt;Adversarial Noise
    &lt;ul&gt;
      &lt;li&gt;Gaussian adversarial noise
        &lt;ul&gt;
          &lt;li&gt;ガウス分布から &lt;script type=&quot;math/tex&quot;&gt;e&lt;/script&gt; をサンプルして、adversarial trainingを適用&lt;/li&gt;
        &lt;/ul&gt;
      &lt;/li&gt;
      &lt;li&gt;Bernoulli adversarial noise
        &lt;ul&gt;
          &lt;li&gt;ベルヌーイ分布から &lt;script type=&quot;math/tex&quot;&gt;e&lt;/script&gt; をサンプルして、adversarial trainingを適用&lt;/li&gt;
          &lt;li&gt;Adversarial dropoutを適用&lt;/li&gt;
        &lt;/ul&gt;
      &lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
&lt;/ul&gt;

&lt;h2 id=&quot;4-どうやって有効だと検証した&quot;&gt;4. どうやって有効だと検証した？&lt;/h2&gt;

&lt;p&gt;Moview review (MR)、The Stanford Sentiment Treebank (SST2)、Customer revirew (CR)、Question type (TREC)、SemEval2010 Task8 (RE)、Answer selection (TreeQA) の
データセットを用いてノイズを用いた各data augmentationの効果を確認している。&lt;/p&gt;

&lt;p&gt;モデルはmulti-channel CNN (Kim, 2014)を利用しており、300次元の学習済みword2vecを単語embeddingとして用いている。&lt;/p&gt;

&lt;h2 id=&quot;5-議論はあるか&quot;&gt;5. 議論はあるか？&lt;/h2&gt;

&lt;ul&gt;
  &lt;li&gt;連続性ノイズと離散性ノイズ
    &lt;ul&gt;
      &lt;li&gt;連続性ノイズ (Gaussian noise, Gaussian adversarial noise) のほうが僅かに離散性ノイズ (Bernoulli noise, Adversarial dropout) より良い結果になった&lt;/li&gt;
      &lt;li&gt;離散性ノイズは効果が強すぎたと考えられる&lt;/li&gt;
      &lt;li&gt;連続性ノイズのほうがエントロピーが大きく、学習に効果があると考えられる&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
  &lt;li&gt;学習データを少なくしたときの効果
    &lt;ul&gt;
      &lt;li&gt;データセットが少ない場合に、ベースラインよりもノイズの摂動が効果を発揮していることが分かる&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;&lt;img src=&quot;/paper-survey/assets/img/nlp/Word-Embedding-Perturbation-for-Sentence-Classification/figure1.png&quot; alt=&quot;Figure 1&quot; /&gt;&lt;/p&gt;

&lt;h2 id=&quot;6-次に読むべき論文はあるか&quot;&gt;6. 次に読むべき論文はあるか？&lt;/h2&gt;

&lt;ul&gt;
  &lt;li&gt;シソーラスを用いた単語の置換
    &lt;ul&gt;
      &lt;li&gt;&lt;a href=&quot;https://arxiv.org/abs/1502.01710&quot;&gt;Zhang, Xiang, and Yann LeCun. “Text understanding from scratch.” arXiv preprint arXiv:1502.01710 (2015).&lt;/a&gt;&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
  &lt;li&gt;単語間の依存関係に着目したdata augmentation
    &lt;ul&gt;
      &lt;li&gt;&lt;a href=&quot;https://arxiv.org/abs/1601.03651&quot;&gt;Xu, Yan, et al. “Improved relation classification by deep recurrent neural networks with data augmentation.” arXiv preprint arXiv:1601.03651 (2016).&lt;/a&gt;&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
  &lt;li&gt;BoWに対してdropoutを適用
    &lt;ul&gt;
      &lt;li&gt;&lt;a href=&quot;http://www.aclweb.org/anthology/P15-1162&quot;&gt;Iyyer, Mohit, et al. “Deep unordered composition rivals syntactic methods for text classification.” Proceedings of the 53rd Annual Meeting of the Association for Computational Linguistics and the 7th International Joint Conference on Natural Language Processing (Volume 1: Long Papers). Vol. 1. 2015.&lt;/a&gt;&lt;/li&gt;
      &lt;li&gt;&lt;a href=&quot;https://link.springer.com/chapter/10.1007/978-3-319-50496-4_59&quot;&gt;Zhang, Dongxu, Tianyi Luo, and Dong Wang. “Learning from LDA using deep neural networks.” Natural Language Understanding and Intelligent Applications. Springer, Cham, 2016. 657-664.&lt;/a&gt;&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
  &lt;li&gt;Adversarial Dropout
    &lt;ul&gt;
      &lt;li&gt;&lt;a href=&quot;https://arxiv.org/abs/1707.03631&quot;&gt;Park, Sungrae, et al. “Adversarial Dropout for Supervised and Semi-supervised Learning.” arXiv preprint arXiv:1707.03631 (2017).&lt;/a&gt;&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
  &lt;li&gt;ベースラインの multi-channel CNN
    &lt;ul&gt;
      &lt;li&gt;&lt;a href=&quot;https://arxiv.org/abs/1408.5882&quot;&gt;Kim, Yoon. “Convolutional neural networks for sentence classification.” arXiv preprint arXiv:1408.5882 (2014).&lt;/a&gt;&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
&lt;/ul&gt;

&lt;h3 id=&quot;論文情報リンク&quot;&gt;論文情報・リンク&lt;/h3&gt;

&lt;ul&gt;
  &lt;li&gt;&lt;a href=&quot;https://arxiv.org/pdf/1804.08166&quot;&gt;Zhang, Dongxu, and Zhichao Yang. “Word Embedding Perturbation for Sentence Classification.” arXiv preprint arXiv:1804.08166 (2018).&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;</content><author><name></name></author><summary type="html">1. どんなもの？</summary></entry><entry><title type="html">Learning to Compute Word Embeddings On the Fly</title><link href="https://shunk031.github.io/paper-survey/summary/nlp/Learning-to-Compute-Word-Embeddings-On-the-Fly" rel="alternate" type="text/html" title="Learning to Compute Word Embeddings On the Fly" /><published>2018-04-01T00:00:00+00:00</published><updated>2018-04-01T00:00:00+00:00</updated><id>https://shunk031.github.io/paper-survey/summary/nlp/Learning-to-Compute-Word-Embeddings-On-the-Fly</id><content type="html" xml:base="https://shunk031.github.io/paper-survey/summary/nlp/Learning-to-Compute-Word-Embeddings-On-the-Fly">&lt;h2 id=&quot;1-どんなもの&quot;&gt;1. どんなもの？&lt;/h2&gt;

&lt;p&gt;OOV問題に対してWordNetの単語定義文をエンコードし未知語に対処する，On the Fly Embdddingsを提案．&lt;/p&gt;

&lt;h2 id=&quot;2-先行研究と比べてどこがすごいの&quot;&gt;2. 先行研究と比べてどこがすごいの？&lt;/h2&gt;

&lt;p&gt;自然言語では頻繁に出現する単語もあるが，ほとんどがZipfian分布に従うような，あまり現れない単語から形成されている．
こうした単語の低頻度の単語はout-of-vocabulary (OOV) 問題として扱われる．&lt;/p&gt;

&lt;p&gt;先行研究ではボキャブラリ外の単語を固定のランダムベクトルで代用する研究があり，効果を示している．
またスペル情報からBi-directional LSTMを用いて，ボキャブラリ外の単語を一般化する先行研究がある．
本研究に最も近い先行研究では，対象となる単語埋め込みに近い辞書定義埋め込みを生成するものがある．&lt;/p&gt;

&lt;p&gt;本研究では特定のタスク対して辞書定義エンコーダをend-to-endで学習を行い，
エンコードした定義文と補助ベクトルを用いてボキャブラリ外の未知語に対応するモデルを提案する．&lt;/p&gt;

&lt;h2 id=&quot;3-技術や手法のキモはどこにある&quot;&gt;3. 技術や手法の”キモ”はどこにある？&lt;/h2&gt;

&lt;p&gt;&lt;img src=&quot;/paper-survey/assets/img/nlp/Learning-to-Compute-Word-Embeddings-On-The-Fly/figure1.png&quot; alt=&quot;Figure 1&quot; /&gt;&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;On the Fly embeddings
    &lt;ul&gt;
      &lt;li&gt;辞書 (WordNet) 定義文をエンコードする &lt;em&gt;definition reader&lt;/em&gt;
        &lt;ul&gt;
          &lt;li&gt;simple mean pooling (MP)&lt;/li&gt;
          &lt;li&gt;mean pooling (MP-L)
            &lt;ul&gt;
              &lt;li&gt;学習可能な行列を辞書内単語ベクトルに掛ける&lt;/li&gt;
            &lt;/ul&gt;
          &lt;/li&gt;
          &lt;li&gt;LSTMの最終ステート&lt;/li&gt;
        &lt;/ul&gt;
      &lt;/li&gt;
      &lt;li&gt;補助ベクトル
        &lt;ul&gt;
          &lt;li&gt;WordNetの定義分からなるベクトル表現&lt;/li&gt;
          &lt;li&gt;単語の文字列情報 (&lt;code class=&quot;highlighter-rouge&quot;&gt;word&lt;/code&gt; -&amp;gt; &lt;code class=&quot;highlighter-rouge&quot;&gt;w&lt;/code&gt;, &lt;code class=&quot;highlighter-rouge&quot;&gt;o&lt;/code&gt;, &lt;code class=&quot;highlighter-rouge&quot;&gt;r&lt;/code&gt;, &lt;code class=&quot;highlighter-rouge&quot;&gt;d&lt;/code&gt;)&lt;/li&gt;
          &lt;li&gt;大規模なデータセットで学習済みのGloVeベクトル&lt;/li&gt;
        &lt;/ul&gt;
      &lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
&lt;/ul&gt;

&lt;h2 id=&quot;4-どうやって有効だと検証した&quot;&gt;4. どうやって有効だと検証した？&lt;/h2&gt;
&lt;p&gt;提案手法に対して Question Answering，Semantic Entailment Classification，Language Modellingの3つのタスクで評価を行っている．&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;Question Answering
    &lt;ul&gt;
      &lt;li&gt;Stanford Question Answering Dataset (SQuAD)を用いて提案手法の評価を行っている．&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
  &lt;li&gt;Semantic Entailment Classification
    &lt;ul&gt;
      &lt;li&gt;Stanford Natural Language Inference (SNLI) コーパスとMulti-Genre Natural Language Inference (MultiNLI) コーパスを用いて提案手法の評価を行っている．&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
  &lt;li&gt;Language Modelling
    &lt;ul&gt;
      &lt;li&gt;One Billion Words (OBW) language modellingタスクで提案手法の評価を行っている．&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
&lt;/ul&gt;

&lt;h2 id=&quot;5-議論はあるか&quot;&gt;5. 議論はあるか？&lt;/h2&gt;

&lt;ul&gt;
  &lt;li&gt;Future work
    &lt;ul&gt;
      &lt;li&gt;複数単語からなる熟語は考慮されていない
        &lt;ul&gt;
          &lt;li&gt;&lt;code class=&quot;highlighter-rouge&quot;&gt;give up&lt;/code&gt; などの熟語&lt;/li&gt;
          &lt;li&gt;&lt;code class=&quot;highlighter-rouge&quot;&gt;San Francisco&lt;/code&gt; のような地名&lt;/li&gt;
        &lt;/ul&gt;
      &lt;/li&gt;
      &lt;li&gt;辞書定義中の未知語への対応&lt;/li&gt;
      &lt;li&gt;循環参照してしまっている単語への対応
        &lt;ul&gt;
          &lt;li&gt;(例 &lt;code class=&quot;highlighter-rouge&quot;&gt;hoge&lt;/code&gt;: &lt;code class=&quot;highlighter-rouge&quot;&gt;fuga&lt;/code&gt;のこと，&lt;code class=&quot;highlighter-rouge&quot;&gt;fuga&lt;/code&gt;: &lt;code class=&quot;highlighter-rouge&quot;&gt;hoge&lt;/code&gt;のこと)&lt;/li&gt;
        &lt;/ul&gt;
      &lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
&lt;/ul&gt;

&lt;h2 id=&quot;6-次に読むべき論文はあるか&quot;&gt;6. 次に読むべき論文はあるか？&lt;/h2&gt;

&lt;ul&gt;
  &lt;li&gt;OOV単語に対して固定のランダムベクトルを適用
    &lt;ul&gt;
      &lt;li&gt;&lt;a href=&quot;https://arxiv.org/abs/1703.00993&quot;&gt;Dhingra, Bhuwan, et al. “A comparative study of word embeddings for reading comprehension.” arXiv preprint arXiv:1703.00993 (2017).&lt;/a&gt;&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
  &lt;li&gt;スペルからOOV単語を一般化する試み
    &lt;ul&gt;
      &lt;li&gt;&lt;a href=&quot;https://arxiv.org/abs/1508.02096&quot;&gt;Ling, Wang, et al. “Finding function in form: Compositional character models for open vocabulary word representation.” arXiv preprint arXiv:1508.02096 (2015).&lt;/a&gt;&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
  &lt;li&gt;対象となる単語埋め込みに近い辞書定義埋め込みを生成
    &lt;ul&gt;
      &lt;li&gt;&lt;a href=&quot;http://www.aclweb.org/anthology/Q16-1002&quot;&gt;Hill, Felix, et al. “Learning to Understand Phrases by Embedding the Dictionary.” Transactions of the Association for Computational Linguistics 4 (2016): 17-30.&lt;/a&gt;&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
&lt;/ul&gt;

&lt;h3 id=&quot;論文情報リンク&quot;&gt;論文情報・リンク&lt;/h3&gt;

&lt;ul&gt;
  &lt;li&gt;&lt;a href=&quot;https://arxiv.org/abs/1706.00286&quot;&gt;Bahdanau, Dzmitry, et al. “Learning to Compute Word Embeddings On the Fly.” arXiv preprint arXiv:1706.00286 (2017).&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;</content><author><name></name></author><summary type="html">1. どんなもの？</summary></entry><entry><title type="html">Glyph-aware Embedding of Chinese Characters</title><link href="https://shunk031.github.io/paper-survey/summary/nlp/Glyph-aware-Embedding-of-Chinese-Characters" rel="alternate" type="text/html" title="Glyph-aware Embedding of Chinese Characters" /><published>2018-03-26T00:00:00+00:00</published><updated>2018-03-26T00:00:00+00:00</updated><id>https://shunk031.github.io/paper-survey/summary/nlp/Glyph-aware-Embedding-of-Chinese-Characters</id><content type="html" xml:base="https://shunk031.github.io/paper-survey/summary/nlp/Glyph-aware-Embedding-of-Chinese-Characters">&lt;h2 id=&quot;1-どんなもの&quot;&gt;1. どんなもの？&lt;/h2&gt;

&lt;p&gt;漢字特有の文字の表意性を明示的に組み込み，文字形状を意識した文字の埋め込み手法を提案．&lt;/p&gt;

&lt;h2 id=&quot;2-先行研究と比べてどこがすごいの&quot;&gt;2. 先行研究と比べてどこがすごいの？&lt;/h2&gt;

&lt;p&gt;英語と比べて中国語は多数の文字が使用され，なおかつ単語と単語の境目が明確ではない．
漢字には形状的な特徴があり，特に”へん”や”つくり”などの部分的な構造が集まり，それら自身が文字の意味・構文的役割・発音などの情報を有している．&lt;/p&gt;

&lt;p&gt;本研究ではこれら漢字の文字形状に着目することで，優れた文字表現の獲得を目指す &lt;em&gt;glyph-aware embedding&lt;/em&gt; を提案している．&lt;/p&gt;

&lt;h2 id=&quot;3-技術や手法のキモはどこにある&quot;&gt;3. 技術や手法の”キモ”はどこにある？&lt;/h2&gt;

&lt;p&gt;&lt;img src=&quot;/paper-survey/assets/img/nlp/Glyph-aware-Embedding-of-Chinese-Characters/figure1.png&quot; alt=&quot;Figure 1&quot; /&gt;&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;CNN embedder
    &lt;ul&gt;
      &lt;li&gt;文字形状を考慮した文字の埋め込みをCNNを用いて実現&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
  &lt;li&gt;ID embedder
    &lt;ul&gt;
      &lt;li&gt;文脈を考慮した文字の埋め込みをLookup tableを用いて実現&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;文字形状のみ考慮した場合，「土」⇆「士」や「人」⇆「入」といった文字形状が似ている文字が近い表現となってしまう場合が考えられる．
そこで文脈を考慮できるLookup tableによるID embeddingを併せて用いることで，この問題を解消している．&lt;/p&gt;

&lt;h2 id=&quot;4-どうやって有効だと検証した&quot;&gt;4. どうやって有効だと検証した？&lt;/h2&gt;

&lt;p&gt;中国語の言語モデリングタスクと中国語の単語分割タスクについて提案手法の精度を検証している．&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;言語モデリングタスク
    &lt;ul&gt;
      &lt;li&gt;embedderで文字表現を得た後，後段のGRUで言語モデルタスクを解いている&lt;/li&gt;
      &lt;li&gt;ベースラインとして全結合層のみからなるlinear embedderを設定&lt;/li&gt;
      &lt;li&gt;Microsoft Research dataset (MSR) を用いて，CNN embedder・ID embedder・ID+CNN embedderそれぞれのperplexityを比較している&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
  &lt;li&gt;単語分割タスク
    &lt;ul&gt;
      &lt;li&gt;embedderで文字表現を得た後，後段のGRU/Bidirectional LSTMで単語分割タスクを解いている&lt;/li&gt;
      &lt;li&gt;Peking University dataset (PKU) および MSRを用いて，CNN embedder・ID embedder・ID+CNN embedderそれぞれの精度を比較している&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;各タスクともCNN embedderが優れた性能を示している．&lt;/p&gt;

&lt;h2 id=&quot;5-議論はあるか&quot;&gt;5. 議論はあるか？&lt;/h2&gt;

&lt;ul&gt;
  &lt;li&gt;入力文字画像にdata augmentationを加えることで精度が向上&lt;/li&gt;
  &lt;li&gt;CNN embedder / ID embedderのパラメータ数について
    &lt;ul&gt;
      &lt;li&gt;埋め込み次元 &lt;script type=&quot;math/tex&quot;&gt;K&lt;/script&gt; ，ボキャブラリサイズ &lt;script type=&quot;math/tex&quot;&gt;V&lt;/script&gt; の場合&lt;/li&gt;
      &lt;li&gt;CNN embedder: &lt;script type=&quot;math/tex&quot;&gt;\mathcal{O}(N+K)&lt;/script&gt;&lt;/li&gt;
      &lt;li&gt;ID embedder: &lt;script type=&quot;math/tex&quot;&gt;\mathcal{O}(NK)&lt;/script&gt;&lt;/li&gt;
      &lt;li&gt;CNN embedderのほうがID embdderよりも少ないパラメータ数で良いパフォーマンスを出していることが分かる&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
&lt;/ul&gt;

&lt;h2 id=&quot;6-次に読むべき論文はあるか&quot;&gt;6. 次に読むべき論文はあるか？&lt;/h2&gt;

&lt;ul&gt;
  &lt;li&gt;&lt;a href=&quot;http://www.aclweb.org/anthology/P15-2098&quot;&gt;Shi, Xinlei, et al. “Radical embedding: Delving deeper to chinese radicals.” Proceedings of the 53rd Annual Meeting of the Association for Computational Linguistics and the 7th International Joint Conference on Natural Language Processing (Volume 2: Short Papers). Vol. 2. 2015.&lt;/a&gt;&lt;/li&gt;
  &lt;li&gt;&lt;a href=&quot;https://arxiv.org/abs/1704.04859&quot;&gt;Liu, Frederick, et al. “Learning character-level compositionality with visual features.” arXiv preprint arXiv:1704.04859 (2017).&lt;/a&gt;&lt;/li&gt;
  &lt;li&gt;&lt;a href=&quot;https://link.springer.com/article/10.1007/s10590-017-9196-0&quot;&gt;Costa-Jussà, Marta R., David Aldón, and José AR Fonollosa. “Chinese–spanish neural machine translation enhanced with character and word bitmap fonts.” Machine Translation 31.1-2 (2017): 35-47.&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;

&lt;h3 id=&quot;論文情報リンク&quot;&gt;論文情報・リンク&lt;/h3&gt;

&lt;ul&gt;
  &lt;li&gt;&lt;a href=&quot;https://arxiv.org/abs/1709.00028&quot;&gt;Dai, Falcon Z., and Zheng Cai. “Glyph-aware Embedding of Chinese Characters.” arXiv preprint arXiv:1709.00028 (2017).&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;</content><author><name></name></author><summary type="html">1. どんなもの？</summary></entry><entry><title type="html">A New Method of Region Embedding for Text Classification</title><link href="https://shunk031.github.io/paper-survey/summary/nlp/A-New-Method-of-Region-Embedding-for-Text-Classification" rel="alternate" type="text/html" title="A New Method of Region Embedding for Text Classification" /><published>2018-02-20T00:00:00+00:00</published><updated>2018-02-20T00:00:00+00:00</updated><id>https://shunk031.github.io/paper-survey/summary/nlp/A-New-Method-of-Region-Embedding-for-Text-Classification</id><content type="html" xml:base="https://shunk031.github.io/paper-survey/summary/nlp/A-New-Method-of-Region-Embedding-for-Text-Classification">&lt;h2 id=&quot;1-どんなもの&quot;&gt;1. どんなもの？&lt;/h2&gt;

&lt;p&gt;CNNやRNNを必要とせずに語順を考慮することができるLocal Context Unitを利用し、タスク固有の単語埋め込み表現を学習するRegion Embeddingを提案。&lt;/p&gt;

&lt;h2 id=&quot;2-先行研究と比べてどこがすごいの&quot;&gt;2. 先行研究と比べてどこがすごいの？&lt;/h2&gt;

&lt;p&gt;文書分類などのタスクにおいて単語の語順を考慮した単語表現にn-gramが用いられることが多いが、
特に &lt;script type=&quot;math/tex&quot;&gt;n&lt;/script&gt; の値が大きいn-gramの場合、モデルが大きくなってしまったり、データスパースネス問題が起こる恐れがある。&lt;/p&gt;

&lt;p&gt;近年ではn-gramを考慮した単語の分散表現を獲得するFastTextが提案されている。
また&lt;a href=&quot;/paper-survey/summry/nlp/Semi-supervised-Convolutional-Neural-Networks-for-Text-Categorization-via-Region-Embedding&quot;&gt;Johnson &amp;amp; Zhang (2015)&lt;/a&gt;では
CNNベースのモデルを用いて単語表現を獲得するregion embeddingという手法を提案しているが、本研究のregion embeddingとは異なり、タスク依存でない点や、教師なし学習の枠組みで学習されている点で異なっている。&lt;/p&gt;

&lt;p&gt;Attentionのみを使用したニューラル機械翻訳モデルであるTransformerは、CNNやRNNを用いずに語順を考慮し、文脈の特徴を学習できていることが示されている。&lt;/p&gt;

&lt;p&gt;本研究ではTransformer参考に、ある単語の周辺のコンテキストを考慮できるLocal context unitを用いて単語の埋め込み表現を獲得するRegion Embeddingを提案し、文書分類タスクで精度が上がることを示している。&lt;/p&gt;

&lt;h2 id=&quot;3-技術や手法のキモはどこにある&quot;&gt;3. 技術や手法の”キモ”はどこにある？&lt;/h2&gt;

&lt;p&gt;&lt;img src=&quot;/paper-survey/assets/img/nlp/A-New-Method-of-Region-Embedding-for-Text-Classification/figure1.png&quot; alt=&quot;Figure 1&quot; /&gt;&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;Region Embedding
    &lt;ul&gt;
      &lt;li&gt;テキスト中の小さな範囲(region)から、局所的な特徴を保持した表現を獲得したい&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
  &lt;li&gt;Local Context Unit
    &lt;ul&gt;
      &lt;li&gt;ある単語の語順と周辺のコンテキストを学習するパラメータ&lt;/li&gt;
      &lt;li&gt;通常のlook up tableを用いたword embedding &lt;script type=&quot;math/tex&quot;&gt;{\bf e}_{w_i}&lt;/script&gt; とlocal context unit &lt;script type=&quot;math/tex&quot;&gt;{\bf K}_{W_i}&lt;/script&gt;を組み合わせた埋め込み表現 &lt;script type=&quot;math/tex&quot;&gt;p^{i}_{w_i}&lt;/script&gt; を学習する&lt;/li&gt;
    &lt;/ul&gt;

    &lt;script type=&quot;math/tex; mode=display&quot;&gt;\begin{align*}
  p^{i}_{w_i + t} = {\bf K}_{w_i, t} \odot {\bf e}_{w_i + t}
\end{align*}&lt;/script&gt;
  &lt;/li&gt;
  &lt;li&gt;Word-Context Region Embedding
    &lt;ul&gt;
      &lt;li&gt;regionの中心の語が前後のコンテキストから受ける影響に焦点を当てたemnedding手法&lt;/li&gt;
      &lt;li&gt;語の出現順によって(特に否定語や強調語など)、意味が逆転する場合を上手く学習することを期待&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
  &lt;li&gt;Context-Word Region Embedding
    &lt;ul&gt;
      &lt;li&gt;Word-Context Region Embeddingとは逆に、コンテキストがregionの中心語から受ける影響に焦点を当てている&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
  &lt;li&gt;Region Embeddingを全結合層で分類&lt;/li&gt;
&lt;/ul&gt;

&lt;h2 id=&quot;4-どうやって有効だと検証した&quot;&gt;4. どうやって有効だと検証した？&lt;/h2&gt;

&lt;p&gt;8つのデータセットを用いて感情分析、新聞記事分類、QAなどのタスクに対して精度を比較している。
ベースラインのn-gram・TFIDFなどの従来の単語表現を用いたモデル、Char-CNN、Char-CRNN、VDCNN、D-LSTM、bigram-FastTextと先行研究のRegion Embeddingを用いた分類器を比較している。
8つのデータセットのうち6つのデータセットで最先端の結果を達成していることが示されている。&lt;/p&gt;

&lt;h2 id=&quot;5-議論はあるか&quot;&gt;5. 議論はあるか？&lt;/h2&gt;

&lt;ul&gt;
  &lt;li&gt;region size / embedding sizeを変えた場合について
    &lt;ul&gt;
      &lt;li&gt;本研究ではregion sizeを7、embedding sizeを128に設定している&lt;/li&gt;
      &lt;li&gt;複数サイズのregion embeddingを組み合わせることで僅かに精度が向上している&lt;/li&gt;
      &lt;li&gt;emnedding sizeを大きくすると従来のFastTextやCNNなどは過学習が見られるが、Region Embeddingはほかと比べてロバストであることが示されている
&lt;img src=&quot;/paper-survey/assets/img/nlp/A-New-Method-of-Region-Embedding-for-Text-Classification/figure2.png&quot; alt=&quot;Figure 2&quot; /&gt;&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
  &lt;li&gt;ある単語における周辺単語の共起について
    &lt;ul&gt;
      &lt;li&gt;“however”についてはhoweverの後が文書分類に重要であることを示している&lt;/li&gt;
      &lt;li&gt;“very”についてはveryの直後の語が重要である etc&lt;/li&gt;
      &lt;li&gt;local context unitが局所的な潜在意味を捉えていることが分かる
&lt;img src=&quot;/paper-survey/assets/img/nlp/A-New-Method-of-Region-Embedding-for-Text-Classification/figure3.png&quot; alt=&quot;Figure 3&quot; /&gt;&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
  &lt;li&gt;感情分析におけるlocal context unitの効果の可視化
    &lt;ul&gt;
      &lt;li&gt;context unitがある場合、正しく形容詞が正しく係り、positive/negativeの判定が正しく行われるようになったことが示されている
&lt;img src=&quot;/paper-survey/assets/img/nlp/A-New-Method-of-Region-Embedding-for-Text-Classification/table4.png&quot; alt=&quot;Table 4&quot; /&gt;&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
&lt;/ul&gt;

&lt;h2 id=&quot;6-次に読むべき論文はあるか&quot;&gt;6. 次に読むべき論文はあるか？&lt;/h2&gt;

&lt;ul&gt;
  &lt;li&gt;FastTextを用いたembeddingについて
    &lt;ul&gt;
      &lt;li&gt;&lt;a href=&quot;https://arxiv.org/abs/1607.01759&quot;&gt;Joulin, Armand, et al. “Bag of tricks for efficient text classification.” arXiv preprint arXiv:1607.01759 (2016).&lt;/a&gt;&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
  &lt;li&gt;CNNを用いたembeddingについて
    &lt;ul&gt;
      &lt;li&gt;&lt;a href=&quot;https://arxiv.org/abs/1412.1058&quot;&gt;Johnson, Rie, and Tong Zhang. “Effective use of word order for text categorization with convolutional neural networks.” arXiv preprint arXiv:1412.1058 (2014).&lt;/a&gt;&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
  &lt;li&gt;Transformerについて
    &lt;ul&gt;
      &lt;li&gt;&lt;a href=&quot;http://papers.nips.cc/paper/7181-attention-is-all-you-need&quot;&gt;Vaswani, Ashish, et al. “Attention is all you need.” Advances in Neural Information Processing Systems. 2017.&lt;/a&gt;&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
  &lt;li&gt;ベースラインのモデルについて
    &lt;ul&gt;
      &lt;li&gt;Char-CNNについて
        &lt;ul&gt;
          &lt;li&gt;&lt;a href=&quot;http://papers.nips.cc/paper/5782-character-level-convolutional-networks-for-text-classifica&quot;&gt;Zhang, Xiang, Junbo Zhao, and Yann LeCun. “Character-level convolutional networks for text classification.” Advances in neural information processing systems. 2015.&lt;/a&gt;&lt;/li&gt;
        &lt;/ul&gt;
      &lt;/li&gt;
      &lt;li&gt;Char-CRNNについて
        &lt;ul&gt;
          &lt;li&gt;&lt;a href=&quot;https://arxiv.org/abs/1602.00367&quot;&gt;Xiao, Yijun, and Kyunghyun Cho. “Efficient character-level document classification by combining convolution and recurrent layers.” arXiv preprint arXiv:1602.00367 (2016).&lt;/a&gt;&lt;/li&gt;
        &lt;/ul&gt;
      &lt;/li&gt;
      &lt;li&gt;VDCNNについて
        &lt;ul&gt;
          &lt;li&gt;&lt;a href=&quot;https://arxiv.org/abs/1606.01781&quot;&gt;Conneau, Alexis, et al. “Very deep convolutional networks for natural language processing.” arXiv preprint arXiv:1606.01781 (2016).&lt;/a&gt;&lt;/li&gt;
        &lt;/ul&gt;
      &lt;/li&gt;
      &lt;li&gt;D-LSTMについて
        &lt;ul&gt;
          &lt;li&gt;&lt;a href=&quot;https://arxiv.org/abs/1703.01898&quot;&gt;Yogatama, Dani, et al. “Generative and discriminative text classification with recurrent neural networks.” arXiv preprint arXiv:1703.01898 (2017).&lt;/a&gt;&lt;/li&gt;
        &lt;/ul&gt;
      &lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
  &lt;li&gt;予測における寄与単語の可視化について
    &lt;ul&gt;
      &lt;li&gt;&lt;a href=&quot;https://arxiv.org/abs/1506.01066&quot;&gt;Li, Jiwei, et al. “Visualizing and understanding neural models in NLP.” arXiv preprint arXiv:1506.01066 (2015).&lt;/a&gt;&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
&lt;/ul&gt;

&lt;h3 id=&quot;論文情報リンク&quot;&gt;論文情報・リンク&lt;/h3&gt;

&lt;ul&gt;
  &lt;li&gt;&lt;a href=&quot;https://openreview.net/forum?id=BkSDMA36Z&quot;&gt;Chao Qiao, Bo Huang, Guocheng Niu, Daren Li, Daxiang Dong, Wei He, Dianhai Yu, Hua Wu, “A New Method of Region Embedding for Text Classification,” International Conference on Learning Representations, 2018&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;</content><author><name></name></author><summary type="html">1. どんなもの？</summary></entry></feed>