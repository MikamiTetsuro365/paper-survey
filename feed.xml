<?xml version="1.0" encoding="utf-8"?><feed xmlns="http://www.w3.org/2005/Atom" ><generator uri="https://jekyllrb.com/" version="3.6.2">Jekyll</generator><link href="https://shunk031.github.io/paper-survey/feed.xml" rel="self" type="application/atom+xml" /><link href="https://shunk031.github.io/paper-survey/" rel="alternate" type="text/html" /><updated>2018-06-18T05:11:25+00:00</updated><id>https://shunk031.github.io/paper-survey/</id><title type="html">Paper Survey</title><subtitle>Survey of previous research and related works on machine learning (especially Deep Learning) in Japanese
</subtitle><entry><title type="html">Joint Embedding of Words and Labels for Text Classification</title><link href="https://shunk031.github.io/paper-survey/summary/nlp/Joint-Embedding-of-Words-and-Labels-for-Text-Classification" rel="alternate" type="text/html" title="Joint Embedding of Words and Labels for Text Classification" /><published>2018-06-17T00:00:00+00:00</published><updated>2018-06-17T00:00:00+00:00</updated><id>https://shunk031.github.io/paper-survey/summary/nlp/Joint-Embedding-of-Words-and-Labels-for-Text-Classification</id><content type="html" xml:base="https://shunk031.github.io/paper-survey/summary/nlp/Joint-Embedding-of-Words-and-Labels-for-Text-Classification">&lt;h2 id=&quot;1-どんなもの&quot;&gt;1. どんなもの？&lt;/h2&gt;

&lt;p&gt;テキスト分類の際に教師ラベルのembeddingと単語のembeddingを組み合わせたattentionの枠組みを用いる、Label-Embedding Attentive Model (LEAM) を提案。&lt;/p&gt;

&lt;h2 id=&quot;2-先行研究と比べてどこがすごいの&quot;&gt;2. 先行研究と比べてどこがすごいの？&lt;/h2&gt;

&lt;p&gt;画像認識分野および自然言語処理分野において、label embeddingを用いたさまざまな枠組みが提案されてきた。近年の自然言語処理分野では単語embeddingやattentionを用いることで、テキスト分類等のタスクの精度向上が示されてきた。
本研究では効果的なattentionモデル構築のためにlabel embeddingを学習する、LEAMを提案している。&lt;/p&gt;

&lt;h2 id=&quot;3-技術や手法のキモはどこにある&quot;&gt;3. 技術や手法の”キモ”はどこにある？&lt;/h2&gt;

&lt;p&gt;&lt;img src=&quot;/paper-survey/assets/img/nlp/Joint-Embedding-of-Words-and-Labels-for-Text-Classification/figure1.png&quot; alt=&quot;Figure 1&quot; /&gt;&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;単語embedding &lt;script type=&quot;math/tex&quot;&gt;{\bf V}&lt;/script&gt; と label embedding &lt;script type=&quot;math/tex&quot;&gt;{\bf C}&lt;/script&gt; から &lt;code class=&quot;highlighter-rouge&quot;&gt;compatibility&lt;/code&gt; &lt;script type=&quot;math/tex&quot;&gt;{\bf G}&lt;/script&gt; を計算&lt;/li&gt;
  &lt;li&gt;softmaxを用いて &lt;script type=&quot;math/tex&quot;&gt;{\bf G}&lt;/script&gt; をnormalizeしたattention &lt;script type=&quot;math/tex&quot;&gt;\beta&lt;/script&gt; を計算&lt;/li&gt;
  &lt;li&gt;単語embeddingとattentionの重み付け平均を計算したdocument embedding &lt;script type=&quot;math/tex&quot;&gt;z&lt;/script&gt; を用いてテキスト分類を行う&lt;/li&gt;
  &lt;li&gt;テスト時にはlabel embedding &lt;script type=&quot;math/tex&quot;&gt;{\bf C}&lt;/script&gt; において、すべてのクラスのembeddingを利用する&lt;/li&gt;
&lt;/ul&gt;

&lt;h2 id=&quot;4-どうやって有効だと検証した&quot;&gt;4. どうやって有効だと検証した？&lt;/h2&gt;

&lt;p&gt;AGNews、Yelp Review Full、Yelp Review Polarity、DBPedia、Yahoo! Answers Topicの5つのデータセットを用いている。
ベースラインのモデルとしてBag-of-words、Shallow/Large word CNN、LSTM、SA-LSTM、Deep CNN、SWEM、fastText、HAN、Bi-BloSANとテキスト分類の精度を比較している。&lt;/p&gt;

&lt;p&gt;上記に加えて医療テキストデータセットであるMIMIC-IIIを用いた実践的な評価を行っている。&lt;/p&gt;

&lt;h2 id=&quot;5-議論はあるか&quot;&gt;5. 議論はあるか？&lt;/h2&gt;

&lt;ul&gt;
  &lt;li&gt;モデルのパラメータ数と学習時間について
    &lt;ul&gt;
      &lt;li&gt;SWEMに次いで少ないパラメータ数と学習時間を実現している&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
  &lt;li&gt;label embeddingの有効性について
    &lt;ul&gt;
      &lt;li&gt;学習から得られたlabel embeddingとdocument embeddingをt-SNEで可視化すると、クラスに対応するlabel embeddingとdocument embeddingに強い相関が見られた
&lt;img src=&quot;/paper-survey/assets/img/nlp/Joint-Embedding-of-Words-and-Labels-for-Text-Classification/figure3.png&quot; alt=&quot;Figure 3&quot; /&gt;&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
  &lt;li&gt;医療テキストに対する有効性について
    &lt;ul&gt;
      &lt;li&gt;attentionを可視化すると、医療に関連する語がハイライトされていることが示されている。
&lt;img src=&quot;/paper-survey/assets/img/nlp/Joint-Embedding-of-Words-and-Labels-for-Text-Classification/figure4.png&quot; alt=&quot;Figure 4&quot; /&gt;&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
&lt;/ul&gt;

&lt;h2 id=&quot;6-次に読むべき論文はあるか&quot;&gt;6. 次に読むべき論文はあるか？&lt;/h2&gt;

&lt;ul&gt;
  &lt;li&gt;画像認識分野におけるlabel embedding
    &lt;ul&gt;
      &lt;li&gt;画像分類
        &lt;ul&gt;
          &lt;li&gt;&lt;a href=&quot;http://ieeexplore.ieee.org/abstract/document/7293699/&quot;&gt;Akata, Zeynep, et al. “Label-embedding for image classification.” IEEE transactions on pattern analysis and machine intelligence 38.7 (2016): 1425-1438.&lt;/a&gt;&lt;/li&gt;
        &lt;/ul&gt;
      &lt;/li&gt;
      &lt;li&gt;マルチモーダル
        &lt;ul&gt;
          &lt;li&gt;&lt;a href=&quot;http://papers.nips.cc/paper/5204-devise-a-deep-visual-semantic-embedding-model&quot;&gt;Frome, Andrea, et al. “Devise: A deep visual-semantic embedding model.” Advances in neural information processing systems. 2013.&lt;/a&gt;&lt;/li&gt;
          &lt;li&gt;&lt;a href=&quot;https://arxiv.org/abs/1411.2539&quot;&gt;Kiros, Ryan, Ruslan Salakhutdinov, and Richard S. Zemel. “Unifying visual-semantic embeddings with multimodal neural language models.” arXiv preprint arXiv:1411.2539 (2014).&lt;/a&gt;&lt;/li&gt;
        &lt;/ul&gt;
      &lt;/li&gt;
      &lt;li&gt;画像中のテキスト認識
        &lt;ul&gt;
          &lt;li&gt;&lt;a href=&quot;http://citeseerx.ist.psu.edu/viewdoc/download?doi=10.1.1.433.2642&amp;amp;rep=rep1&amp;amp;type=pdf&quot;&gt;Rodriguez-Serrano, Jose A., Florent Perronnin, and France Meylan. “Label embedding for text recognition.” Proceedings of the British Machine Vision Conference. 2013.&lt;/a&gt;&lt;/li&gt;
        &lt;/ul&gt;
      &lt;/li&gt;
      &lt;li&gt;Zero-shot learning
        &lt;ul&gt;
          &lt;li&gt;&lt;a href=&quot;http://papers.nips.cc/paper/3650-zero-shot-learning-with-semantic-output-codes&quot;&gt;Palatucci, Mark, et al. “Zero-shot learning with semantic output codes.” Advances in neural information processing systems. 2009.&lt;/a&gt;&lt;/li&gt;
          &lt;li&gt;&lt;a href=&quot;http://www.aclweb.org/anthology/P15-2048&quot;&gt;Yogatama, Dani, Daniel Gillick, and Nevena Lazic. “Embedding methods for fine grained entity type classification.” Proceedings of the 53rd Annual Meeting of the Association for Computational Linguistics and the 7th International Joint Conference on Natural Language Processing (Volume 2: Short Papers). Vol. 2. 2015.&lt;/a&gt;&lt;/li&gt;
          &lt;li&gt;&lt;a href=&quot;http://www.aclweb.org/anthology/C16-1017&quot;&gt;Ma, Yukun, Erik Cambria, and Sa Gao. “Label embedding for zero-shot fine-grained named entity typing.” Proceedings of COLING 2016, the 26th International Conference on Computational Linguistics: Technical Papers. 2016.&lt;/a&gt;&lt;/li&gt;
        &lt;/ul&gt;
      &lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
  &lt;li&gt;自然言語処理におけるlabel embedding
    &lt;ul&gt;
      &lt;li&gt;Heterogeneous networkによるlabel embedding
        &lt;ul&gt;
          &lt;li&gt;&lt;a href=&quot;https://dl.acm.org/citation.cfm?id=2783307&quot;&gt;Tang, Jian, Meng Qu, and Qiaozhu Mei. “Pte: Predictive text embedding through large-scale heterogeneous text networks.” Proceedings of the 21th ACM SIGKDD International Conference on Knowledge Discovery and Data Mining. ACM, 2015.&lt;/a&gt;&lt;/li&gt;
        &lt;/ul&gt;
      &lt;/li&gt;
      &lt;li&gt;マルチタスク学習
        &lt;ul&gt;
          &lt;li&gt;&lt;a href=&quot;http://papers.nips.cc/paper/7005-deconvolutional-paragraph-representation-learning&quot;&gt;Zhang, Yizhe, et al. “Deconvolutional paragraph representation learning.” Advances in Neural Information Processing Systems. 2017.&lt;/a&gt;&lt;/li&gt;
        &lt;/ul&gt;
      &lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
  &lt;li&gt;ベースラインのモデルについて
    &lt;ul&gt;
      &lt;li&gt;Bag-of-words、Shallow/Large word CNN、LSTM
        &lt;ul&gt;
          &lt;li&gt;&lt;a href=&quot;http://papers.nips.cc/paper/5782-character-level-convolutional-networks-for-text-classifica&quot;&gt;Zhang, Xiang, Junbo Zhao, and Yann LeCun. “Character-level convolutional networks for text classification.” Advances in neural information processing systems. 2015.&lt;/a&gt;&lt;/li&gt;
        &lt;/ul&gt;
      &lt;/li&gt;
      &lt;li&gt;SA-LSTM
        &lt;ul&gt;
          &lt;li&gt;&lt;a href=&quot;http://papers.nips.cc/paper/5949-semi-supervised-sequence-learning&quot;&gt;Dai, Andrew M., and Quoc V. Le. “Semi-supervised sequence learning.” Advances in Neural Information Processing Systems. 2015.&lt;/a&gt;&lt;/li&gt;
        &lt;/ul&gt;
      &lt;/li&gt;
      &lt;li&gt;Deep CNN
        &lt;ul&gt;
          &lt;li&gt;&lt;a href=&quot;http://www.aclweb.org/anthology/E17-1104&quot;&gt;Conneau, Alexis, et al. “Very deep convolutional networks for text classification.” Proceedings of the 15th Conference of the European Chapter of the Association for Computational Linguistics: Volume 1, Long Papers. Vol. 1. 2017.&lt;/a&gt;&lt;/li&gt;
        &lt;/ul&gt;
      &lt;/li&gt;
      &lt;li&gt;SWEM
        &lt;ul&gt;
          &lt;li&gt;&lt;a href=&quot;https://arxiv.org/abs/1805.09843&quot;&gt;Shen, Dinghan, et al. “Baseline needs more love: On simple word-embedding-based models and associated pooling mechanisms.” arXiv preprint arXiv:1805.09843 (2018).&lt;/a&gt;&lt;/li&gt;
        &lt;/ul&gt;
      &lt;/li&gt;
      &lt;li&gt;HAN
        &lt;ul&gt;
          &lt;li&gt;&lt;a href=&quot;http://www.aclweb.org/anthology/N16-1174&quot;&gt;Yang, Zichao, et al. “Hierarchical attention networks for document classification.” Proceedings of the 2016 Conference of the North American Chapter of the Association for Computational Linguistics: Human Language Technologies. 2016.&lt;/a&gt;&lt;/li&gt;
        &lt;/ul&gt;
      &lt;/li&gt;
      &lt;li&gt;Bi-BloSAN
        &lt;ul&gt;
          &lt;li&gt;&lt;a href=&quot;https://arxiv.org/abs/1804.00857&quot;&gt;Shen, Tao, et al. “Bi-directional block self-attention for fast and memory-efficient sequence modeling.” arXiv preprint arXiv:1804.00857 (2018).&lt;/a&gt;&lt;/li&gt;
        &lt;/ul&gt;
      &lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
&lt;/ul&gt;

&lt;h3 id=&quot;論文情報リンク&quot;&gt;論文情報・リンク&lt;/h3&gt;

&lt;ul&gt;
  &lt;li&gt;&lt;a href=&quot;https://arxiv.org/pdf/1805.04174&quot;&gt;Wang, Guoyin, et al. “Joint Embedding of Words and Labels for Text Classification.” arXiv preprint arXiv:1805.04174 (2018).&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;</content><author><name></name></author><summary type="html">1. どんなもの？</summary></entry><entry><title type="html">Learn to Pay Attention</title><link href="https://shunk031.github.io/paper-survey/summary/cv/Learn-to-Pay-Attention" rel="alternate" type="text/html" title="Learn to Pay Attention" /><published>2018-06-16T00:00:00+00:00</published><updated>2018-06-16T00:00:00+00:00</updated><id>https://shunk031.github.io/paper-survey/summary/cv/Learn-to-Pay-Attention</id><content type="html" xml:base="https://shunk031.github.io/paper-survey/summary/cv/Learn-to-Pay-Attention">&lt;h2 id=&quot;1-どんなもの&quot;&gt;1. どんなもの？&lt;/h2&gt;

&lt;p&gt;画像認識に対して学習可能なattention機構をCNNに導入し、baseline手法を超える精度を実現&lt;/p&gt;

&lt;h2 id=&quot;2-先行研究と比べてどこがすごいの&quot;&gt;2. 先行研究と比べてどこがすごいの？&lt;/h2&gt;

&lt;p&gt;Convolutional Neural Network (CNN) は画像処理分野で素晴らしい結果を残しているが、こうした問題に対してモデルが推論する過程が不透明であり、結果の考察が難しい。
そこで先行研究ではモデルの解釈性の向上のために、推論する画像のどの部分に注目しているかを可視化する手法が複数提案されている。
しかしながらこれらの手法は学習済みのモデルに対してのみ適用可能という制限がある。&lt;/p&gt;

&lt;p&gt;Attention機構は学習時に入力のどの部分に注視するかを学習することが可能であり、機械翻訳や画像に対する説明文自動生成(キャプショニング)、VQAなどにおいて精度向上に寄与している。&lt;/p&gt;

&lt;p&gt;Attentionを計算する場合にクエリが必要な画像キャプションやVQAに対して、本研究ではattentionを推定するためにglobalな画像表現を利用し、分類問題においてもattention機構を導入することに成功している。&lt;/p&gt;

&lt;h2 id=&quot;3-技術や手法のキモはどこにある&quot;&gt;3. 技術や手法の”キモ”はどこにある？&lt;/h2&gt;

&lt;p&gt;&lt;img src=&quot;/paper-survey/assets/img/cv/Learn-to-Pay-Attention/figure2.png&quot; alt=&quot;Figure 2&quot; /&gt;&lt;/p&gt;

&lt;p&gt;&lt;code class=&quot;highlighter-rouge&quot;&gt;local feature vector&lt;/code&gt; と &lt;code class=&quot;highlighter-rouge&quot;&gt;global feature vector&lt;/code&gt; を用いたattention機構を実現した。&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;畳み込み層から活性化関数を通して得られるlocal feature vector &lt;script type=&quot;math/tex&quot;&gt;\mathcal{L}&lt;/script&gt; と最終全結合層の出力であるglobal feature vector &lt;script type=&quot;math/tex&quot;&gt;\mathcal{G}&lt;/script&gt; から、&lt;code class=&quot;highlighter-rouge&quot;&gt;compatibility score&lt;/code&gt; &lt;script type=&quot;math/tex&quot;&gt;C\left(\hat{\mathcal{L}}, \mathcal{G} \right)&lt;/script&gt; を計算し、各local feature vectorの重要度 &lt;script type=&quot;math/tex&quot;&gt;\mathcal{A}&lt;/script&gt; (attention) を算出する&lt;/li&gt;
  &lt;li&gt;重要度 &lt;script type=&quot;math/tex&quot;&gt;\mathcal{A}&lt;/script&gt; とlocal feature vectorとの重み付き平均 &lt;script type=&quot;math/tex&quot;&gt;\mathcal{G}_a&lt;/script&gt; を計算する&lt;/li&gt;
  &lt;li&gt;各畳み込み層から得られる複数の &lt;script type=&quot;math/tex&quot;&gt;\mathcal{G}_a&lt;/script&gt; をconcatしたベクトルを用いて分類を行う&lt;/li&gt;
  &lt;li&gt;&lt;code class=&quot;highlighter-rouge&quot;&gt;compatibility socre&lt;/code&gt; を計算する際に用いる &lt;script type=&quot;math/tex&quot;&gt;\mathcal{C}&lt;/script&gt; は ドット積 を利用した&lt;/li&gt;
&lt;/ul&gt;

&lt;h2 id=&quot;4-どうやって有効だと検証した&quot;&gt;4. どうやって有効だと検証した？&lt;/h2&gt;

&lt;p&gt;ベースラインとして、先行研究のVGG-GAPおよびVGG-PAN、ResNet164と、VGG/ResNetに対して本研究のattention機構を導入できるようパラメータを調整したネットワークを比較している。
global feature vectorとlocal feature vectorに対してcompatibility scoreを計算する際にドット積を用いた&lt;code class=&quot;highlighter-rouge&quot;&gt;dp&lt;/code&gt;と、パラメータを用いた&lt;code class=&quot;highlighter-rouge&quot;&gt;pc&lt;/code&gt;を比較している。&lt;/p&gt;

&lt;p&gt;評価に用いるデータセットはCIFAR10/100、CUB-200-2011、SVHN等を利用している。また導入したattention機構がadversarialなサンプルに対してもロバストであることを示す実験も行っている。&lt;/p&gt;

&lt;h2 id=&quot;5-議論はあるか&quot;&gt;5. 議論はあるか？&lt;/h2&gt;

&lt;p&gt;&lt;img src=&quot;/paper-survey/assets/img/cv/Learn-to-Pay-Attention/figure3.png&quot; alt=&quot;Figure 3&quot; /&gt;&lt;/p&gt;

&lt;p&gt;提案手法 (proposed) と既存手法 (existing) それぞれのattention mapを可視化した結果である。提案手法がよりdiscriminativeな形で物体を認識していることが示されている。&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;/paper-survey/assets/img/cv/Learn-to-Pay-Attention/figure4.png&quot; alt=&quot;Figure 4&quot; /&gt;&lt;/p&gt;

&lt;p&gt;CUB-200データセットで学習した提案手法の結果である。10層目は目の特徴を捉えており、13層目は体全体を捉えていることが示されている。&lt;/p&gt;

&lt;h2 id=&quot;6-次に読むべき論文はあるか&quot;&gt;6. 次に読むべき論文はあるか？&lt;/h2&gt;

&lt;ul&gt;
  &lt;li&gt;モデルの解釈性向上のための可視化手法
    &lt;ul&gt;
      &lt;li&gt;&lt;a href=&quot;https://arxiv.org/abs/1312.6034&quot;&gt;Simonyan, Karen, Andrea Vedaldi, and Andrew Zisserman. “Deep inside convolutional networks: Visualising image classification models and saliency maps.” arXiv preprint arXiv:1312.6034 (2013).&lt;/a&gt;&lt;/li&gt;
      &lt;li&gt;&lt;a href=&quot;http://openaccess.thecvf.com/content_iccv_2015/papers/Cao_Look_and_Think_ICCV_2015_paper.pdf&quot;&gt;Cao, Chunshui, et al. “Look and think twice: Capturing top-down visual attention with feedback convolutional neural networks.” Proceedings of the IEEE International Conference on Computer Vision. 2015.&lt;/a&gt;&lt;/li&gt;
      &lt;li&gt;Global average pooling (GAP)
        &lt;ul&gt;
          &lt;li&gt;&lt;a href=&quot;https://www.cv-foundation.org/openaccess/content_cvpr_2016/papers/Zhou_Learning_Deep_Features_CVPR_2016_paper.pdf&quot;&gt;Zhou, Bolei, et al. “Learning deep features for discriminative Computer.” localization Vision and Pattern Recognition (CVPR), 2016 IEEE Conference on. IEEE, 2016.&lt;/a&gt;&lt;/li&gt;
        &lt;/ul&gt;
      &lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
  &lt;li&gt;Attention機構が用いられている先行研究
    &lt;ul&gt;
      &lt;li&gt;属性予測 (Progressive Attention Networks (PAN))
        &lt;ul&gt;
          &lt;li&gt;&lt;a href=&quot;http://adsabs.harvard.edu/abs/2016arXiv160602393H&quot;&gt;Hongsuck Seo, Paul, et al. “Progressive Attention Networks for Visual Attribute Prediction.” arXiv preprint arXiv:1606.02393 (2016).&lt;/a&gt;&lt;/li&gt;
        &lt;/ul&gt;
      &lt;/li&gt;
      &lt;li&gt;機械翻訳
        &lt;ul&gt;
          &lt;li&gt;&lt;a href=&quot;https://arxiv.org/abs/1409.0473&quot;&gt;Bahdanau, Dzmitry, Kyunghyun Cho, and Yoshua Bengio. “Neural machine translation by jointly learning to align and translate.” arXiv preprint arXiv:1409.0473 (2014).&lt;/a&gt;&lt;/li&gt;
        &lt;/ul&gt;
      &lt;/li&gt;
      &lt;li&gt;画像に対する説明文自動生成
        &lt;ul&gt;
          &lt;li&gt;&lt;a href=&quot;http://www.jmlr.org/proceedings/papers/v37/xuc15.pdf&quot;&gt;Xu, Kelvin, et al. “Show, attend and tell: Neural image caption generation with visual attention.” International Conference on Machine Learning. 2015.&lt;/a&gt;&lt;/li&gt;
          &lt;li&gt;&lt;a href=&quot;http://openaccess.thecvf.com/content_cvpr_2016/papers/You_Image_Captioning_With_CVPR_2016_paper.pdf&quot;&gt;You, Quanzeng, et al. “Image captioning with semantic attention.” Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition. 2016.&lt;/a&gt;&lt;/li&gt;
          &lt;li&gt;&lt;a href=&quot;http://www.aaai.org/ocs/index.php/AAAI/AAAI17/paper/download/14888/14305&quot;&gt;Mun, Jonghwan, Minsu Cho, and Bohyung Han. “Text-Guided Attention Model for Image Captioning.” AAAI. 2017.&lt;/a&gt;&lt;/li&gt;
        &lt;/ul&gt;
      &lt;/li&gt;
      &lt;li&gt;Visual question answering (VQA)
        &lt;ul&gt;
          &lt;li&gt;&lt;a href=&quot;https://link.springer.com/chapter/10.1007/978-3-319-46478-7_28&quot;&gt;Xu, Huijuan, and Kate Saenko. “Ask, attend and answer: Exploring question-guided spatial attention for visual question answering.” European Conference on Computer Vision. Springer, Cham, 2016.&lt;/a&gt;&lt;/li&gt;
          &lt;li&gt;&lt;a href=&quot;https://www.cv-foundation.org/openaccess/content_cvpr_2016/app/S01-03.pdf&quot;&gt;Yang, Zichao, et al. “Stacked attention networks for image question answering.” Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition. 2016.&lt;/a&gt;&lt;/li&gt;
        &lt;/ul&gt;
      &lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
&lt;/ul&gt;

&lt;h3 id=&quot;論文情報リンク&quot;&gt;論文情報・リンク&lt;/h3&gt;

&lt;ul&gt;
  &lt;li&gt;&lt;a href=&quot;https://arxiv.org/abs/1804.02391&quot;&gt;Jetley, Saumya, et al. “Learn to pay attention.” arXiv preprint arXiv:1804.02391 (2018).&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;</content><author><name></name></author><summary type="html">1. どんなもの？</summary></entry><entry><title type="html">Skin Lesion Analysis Toward Melanoma Detection: A Challenge at the 2017 International Symposium on Biomedical Imaging (ISBI), Hosted by the International Skin Imaging Collaboration (ISIC)</title><link href="https://shunk031.github.io/paper-survey/summary/others/Skin-Lesion-Analysis-Toward-Melanoma-Detection-A-Challenge-at-the-2017-International-Symposium-on-Biomedical-Imaging-ISBI-Hosted-by-the-International-Skin-Imaging-Collaboration-ISIC" rel="alternate" type="text/html" title="Skin Lesion Analysis Toward Melanoma Detection: A Challenge at the 2017 International Symposium on Biomedical Imaging (ISBI), Hosted by the International Skin Imaging Collaboration (ISIC) " /><published>2018-06-03T00:00:00+00:00</published><updated>2018-06-03T00:00:00+00:00</updated><id>https://shunk031.github.io/paper-survey/summary/others/Skin-Lesion-Analysis-Toward-Melanoma-Detection-A-Challenge-at-the-2017-International-Symposium-on-Biomedical-Imaging-ISBI-Hosted-by-the-International-Skin-Imaging-Collaboration-ISIC</id><content type="html" xml:base="https://shunk031.github.io/paper-survey/summary/others/Skin-Lesion-Analysis-Toward-Melanoma-Detection-A-Challenge-at-the-2017-International-Symposium-on-Biomedical-Imaging-ISBI-Hosted-by-the-International-Skin-Imaging-Collaboration-ISIC">&lt;h2 id=&quot;1-どんなもの&quot;&gt;1. どんなもの？&lt;/h2&gt;

&lt;p&gt;ISIC2017で行われたメラノーマ画像の分析チャレンジの内容をまとめたもの&lt;/p&gt;

&lt;h2 id=&quot;2-先行研究と比べてどこがすごい&quot;&gt;2. 先行研究と比べてどこがすごい？&lt;/h2&gt;

&lt;ul&gt;
  &lt;li&gt;ISIC2017では3種類のタスクが公開された
    &lt;ul&gt;
      &lt;li&gt;Lesion Segmentation Task&lt;/li&gt;
      &lt;li&gt;Dermoscopic Feature Classification&lt;/li&gt;
      &lt;li&gt;Disease Classification Task
        &lt;ul&gt;
          &lt;li&gt;3カテゴリ (melanoma, nevus, seborrheic keratosis) をそれぞれ分類するタスク&lt;/li&gt;
          &lt;li&gt;melanoma (train: 374, val: 30, test: 117)&lt;/li&gt;
          &lt;li&gt;nevus (train: 1372, val: 78, test: 393)&lt;/li&gt;
          &lt;li&gt;seborrheic keratosis (train: 254, val: 42, test: 90)&lt;/li&gt;
        &lt;/ul&gt;
      &lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
  &lt;li&gt;データセットは以下から入手できる
    &lt;ul&gt;
      &lt;li&gt;&lt;a href=&quot;http://challenge2017.isic-archive.com/&quot;&gt;http://challenge2017.isic-archive.com/&lt;/a&gt;&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
&lt;/ul&gt;

&lt;h2 id=&quot;3-技術や手法のキモはどこ&quot;&gt;3. 技術や手法のキモはどこ？&lt;/h2&gt;

&lt;ul&gt;
  &lt;li&gt;平均スコアがベストだったモデル
    &lt;ul&gt;
      &lt;li&gt;&lt;a href=&quot;https://arxiv.org/abs/1703.03108&quot;&gt;Matsunaga, Kazuhisa, et al. “Image classification of melanoma, nevus and seborrheic keratosis by deep neural network ensemble.” arXiv preprint arXiv:1703.03108 (2017).&lt;/a&gt;&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
  &lt;li&gt;Melanoma予測精度がベストだったモデル
    &lt;ul&gt;
      &lt;li&gt;&lt;a href=&quot;https://arxiv.org/abs/1703.01976&quot;&gt;Díaz, Iván González. “Incorporating the knowledge of dermatologists to convolutional neural networks for the diagnosis of skin lesions.” arXiv preprint arXiv:1703.01976 (2017).&lt;/a&gt;&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
  &lt;li&gt;Seborrheic keratosis予測精度がベストだったモデル
    &lt;ul&gt;
      &lt;li&gt;&lt;a href=&quot;https://arxiv.org/abs/1703.04819&quot;&gt;Menegola, Afonso, et al. “RECOD titans at ISIC challenge 2017.” arXiv preprint arXiv:1703.04819 (2017).&lt;/a&gt;&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
&lt;/ul&gt;

&lt;h3 id=&quot;予測モデルのトレンド&quot;&gt;予測モデルのトレンド&lt;/h3&gt;
&lt;ul&gt;
  &lt;li&gt;深層学習モデルを複数アンサンブルしている
    &lt;ul&gt;
      &lt;li&gt;学習データに追加で外部データを用いている&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
  &lt;li&gt;Seborrheic keratosiの分類はMelanomaの分類に比べて容易な傾向だった
    &lt;ul&gt;
      &lt;li&gt;病気の性質・データの偏りから生じたものでは&lt;/li&gt;
      &lt;li&gt;一番ベストなモデルを作ったチームは追加でヒューリスティックなラベリングを追加で行っている&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
  &lt;li&gt;平均スコアがベストだったモデルは、各カテゴリ分類ではベストなモデルではなかった&lt;/li&gt;
  &lt;li&gt;一番複雑なモデルはパフォーマンスを下げており、シンプルなモデルは全体のパフォーマンスを上げている&lt;/li&gt;
  &lt;li&gt;予測の閾値は重要そう。確率的なスコア標準化(Probablistic score normalization)はsensitivityおよびspecificityのスコアをあげるために効果がありそう [&lt;a href=&quot;http://ieeexplore.ieee.org/abstract/document/8030303/&quot;&gt;Codella+&lt;/a&gt;, &lt;a href=&quot;https://www.jaad.org/article/S0190-9622(17)32202-8/fulltext&quot;&gt;Marchetti+&lt;/a&gt;]。&lt;/li&gt;
&lt;/ul&gt;

&lt;h2 id=&quot;4-どうやって有効だと検証した&quot;&gt;4. どうやって有効だと検証した？&lt;/h2&gt;

&lt;ul&gt;
  &lt;li&gt;評価尺度
    &lt;ul&gt;
      &lt;li&gt;AUC, specificity (melanoma classification)&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
&lt;/ul&gt;

&lt;h2 id=&quot;5-議論はある&quot;&gt;5. 議論はある？&lt;/h2&gt;

&lt;ul&gt;
  &lt;li&gt;Classficationタスクについて
    &lt;ul&gt;
      &lt;li&gt;モデルのアンサンブルと追加の外部データ使用が高いパフォーマンスを出すカギになる&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
&lt;/ul&gt;

&lt;h2 id=&quot;6-次に読むべき論文は&quot;&gt;6. 次に読むべき論文は？&lt;/h2&gt;

&lt;ul&gt;
  &lt;li&gt;&lt;a href=&quot;https://arxiv.org/abs/1703.03108&quot;&gt;Matsunaga, Kazuhisa, et al. “Image classification of melanoma, nevus and seborrheic keratosis by deep neural network ensemble.” arXiv preprint arXiv:1703.03108 (2017).&lt;/a&gt;&lt;/li&gt;
  &lt;li&gt;&lt;a href=&quot;https://arxiv.org/abs/1703.01976&quot;&gt;Díaz, Iván González. “Incorporating the knowledge of dermatologists to convolutional neural networks for the diagnosis of skin lesions.” arXiv preprint arXiv:1703.01976 (2017).&lt;/a&gt;&lt;/li&gt;
  &lt;li&gt;&lt;a href=&quot;https://arxiv.org/abs/1703.04819&quot;&gt;Menegola, Afonso, et al. “RECOD titans at ISIC challenge 2017.” arXiv preprint arXiv:1703.04819 (2017).&lt;/a&gt;&lt;/li&gt;
  &lt;li&gt;&lt;a href=&quot;http://ieeexplore.ieee.org/abstract/document/8030303/&quot;&gt;Codella, Noel CF, et al. “Deep learning ensembles for melanoma recognition in dermoscopy images.” IBM Journal of Research and Development 61.4 (2017): 5-1.&lt;/a&gt;&lt;/li&gt;
  &lt;li&gt;&lt;a href=&quot;https://www.jaad.org/article/S0190-9622(17)32202-8/fulltext&quot;&gt;Marchetti, Michael A., et al. “Results of the 2016 International Skin Imaging Collaboration International Symposium on Biomedical Imaging challenge: Comparison of the accuracy of computer algorithms to dermatologists for the diagnosis of melanoma from dermoscopic images.” Journal of the American Academy of Dermatology 78.2 (2018): 270-277.&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;

&lt;h2 id=&quot;論文情報リンク&quot;&gt;論文情報・リンク&lt;/h2&gt;

&lt;ul&gt;
  &lt;li&gt;&lt;a href=&quot;https://arxiv.org/abs/1710.05006&quot;&gt;Codella, Noel CF, et al. “Skin lesion analysis toward melanoma detection: A challenge at the 2017 international symposium on biomedical imaging (isbi), hosted by the international skin imaging collaboration (isic).” arXiv preprint arXiv:1710.05006 (2017).&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;</content><author><name></name></author><summary type="html">1. どんなもの？</summary></entry><entry><title type="html">RECOD Titans at ISIC Challenge 2017</title><link href="https://shunk031.github.io/paper-survey/summary/others/RECOD-Titans-at-ISIC-Challenge-2017" rel="alternate" type="text/html" title="RECOD Titans at ISIC Challenge 2017" /><published>2018-06-02T00:00:00+00:00</published><updated>2018-06-02T00:00:00+00:00</updated><id>https://shunk031.github.io/paper-survey/summary/others/RECOD-Titans-at-ISIC-Challenge-2017</id><content type="html" xml:base="https://shunk031.github.io/paper-survey/summary/others/RECOD-Titans-at-ISIC-Challenge-2017">&lt;h2 id=&quot;1-どんなもの&quot;&gt;1. どんなもの？&lt;/h2&gt;

&lt;p&gt;ISIC2017メラノーマ画像分析でSeborrheic keratosis分類タスクでベストな精度を出したモデルの解説&lt;/p&gt;

&lt;h2 id=&quot;2-先行研究と比べてどこがすごい&quot;&gt;2. 先行研究と比べてどこがすごい？&lt;/h2&gt;

&lt;ul&gt;
  &lt;li&gt;以前までの問題点
    &lt;ul&gt;
      &lt;li&gt;学習データ量が足りない&lt;/li&gt;
      &lt;li&gt;モデルの深さ&lt;/li&gt;
      &lt;li&gt;計算コスト&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;これらに対して、外部の追加データの使用・ResNet等の深いネットワークの使用・クラウドベースの計算機を使用している。&lt;/p&gt;

&lt;h2 id=&quot;3-技術や手法のキモはどこ&quot;&gt;3. 技術や手法のキモはどこ？&lt;/h2&gt;

&lt;h3 id=&quot;外部データを用いて学習データを増やす&quot;&gt;外部データを用いて学習データを増やす&lt;/h3&gt;

&lt;table&gt;
  &lt;thead&gt;
    &lt;tr&gt;
      &lt;th&gt;Dataset&lt;/th&gt;
      &lt;th style=&quot;text-align: center&quot;&gt;# of melanoma&lt;/th&gt;
      &lt;th style=&quot;text-align: center&quot;&gt;# of seborrheic keratoses&lt;/th&gt;
      &lt;th style=&quot;text-align: center&quot;&gt;# of benign nevi&lt;/th&gt;
    &lt;/tr&gt;
  &lt;/thead&gt;
  &lt;tbody&gt;
    &lt;tr&gt;
      &lt;td&gt;ISIC 2017 Challenge&lt;/td&gt;
      &lt;td style=&quot;text-align: center&quot;&gt;374&lt;/td&gt;
      &lt;td style=&quot;text-align: center&quot;&gt;254&lt;/td&gt;
      &lt;td style=&quot;text-align: center&quot;&gt;1372&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td&gt;ISIC Archive&lt;/td&gt;
      &lt;td style=&quot;text-align: center&quot;&gt;(13000 dermoscopic images)&lt;/td&gt;
      &lt;td style=&quot;text-align: center&quot;&gt;—&lt;/td&gt;
      &lt;td style=&quot;text-align: center&quot;&gt;—&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td&gt;Interactive Atlas of Dermoscopy&lt;/td&gt;
      &lt;td style=&quot;text-align: center&quot;&gt;270&lt;/td&gt;
      &lt;td style=&quot;text-align: center&quot;&gt;49&lt;/td&gt;
      &lt;td style=&quot;text-align: center&quot;&gt;—&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td&gt;Dermofit Image Library&lt;/td&gt;
      &lt;td style=&quot;text-align: center&quot;&gt;76&lt;/td&gt;
      &lt;td style=&quot;text-align: center&quot;&gt;257&lt;/td&gt;
      &lt;td style=&quot;text-align: center&quot;&gt;—&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td&gt;IRMA Skin Lesion Dataset&lt;/td&gt;
      &lt;td style=&quot;text-align: center&quot;&gt;187&lt;/td&gt;
      &lt;td style=&quot;text-align: center&quot;&gt;—&lt;/td&gt;
      &lt;td style=&quot;text-align: center&quot;&gt;—&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td&gt;PH2 Datset&lt;/td&gt;
      &lt;td style=&quot;text-align: center&quot;&gt;40&lt;/td&gt;
      &lt;td style=&quot;text-align: center&quot;&gt;—&lt;/td&gt;
      &lt;td style=&quot;text-align: center&quot;&gt;—&lt;/td&gt;
    &lt;/tr&gt;
  &lt;/tbody&gt;
&lt;/table&gt;

&lt;ul&gt;
  &lt;li&gt;すべてのデータについて、アノテーションされているラベルを考慮してマージする
    &lt;ul&gt;
      &lt;li&gt;以下のデータについては除いている
        &lt;ul&gt;
          &lt;li&gt;ISIC Archiveの診断結果がない画像&lt;/li&gt;
          &lt;li&gt;Atlasの &lt;code class=&quot;highlighter-rouge&quot;&gt;miscellaneous&lt;/code&gt; クラス&lt;/li&gt;
          &lt;li&gt;IRMAの &lt;code class=&quot;highlighter-rouge&quot;&gt;benign&lt;/code&gt; クラス&lt;/li&gt;
          &lt;li&gt;PH2の &lt;code class=&quot;highlighter-rouge&quot;&gt;atypical nevi&lt;/code&gt; クラス&lt;/li&gt;
        &lt;/ul&gt;
      &lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
  &lt;li&gt;ISIC Archiveにおいて、benignのデータの多くが15歳の患者だった
    &lt;ul&gt;
      &lt;li&gt;これらを取り除いたらスコアが微増&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
  &lt;li&gt;各データセット間で重複してるデータが存在している
    &lt;ul&gt;
      &lt;li&gt;trainとvalidationに分けるときに注意しないといけない&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
  &lt;li&gt;&lt;code class=&quot;highlighter-rouge&quot;&gt;deploy&lt;/code&gt; データ群と &lt;code class=&quot;highlighter-rouge&quot;&gt;semi&lt;/code&gt; データ群を学習用に作成
    &lt;ul&gt;
      &lt;li&gt;&lt;code class=&quot;highlighter-rouge&quot;&gt;deploy&lt;/code&gt;
        &lt;ul&gt;
          &lt;li&gt;6つのデータセットからなる9640枚の学習画像
            &lt;ul&gt;
              &lt;li&gt;keratosis分類ではこのデータ群で学習したほうがAUCスコアが良かった&lt;/li&gt;
            &lt;/ul&gt;
          &lt;/li&gt;
        &lt;/ul&gt;
      &lt;/li&gt;
      &lt;li&gt;&lt;code class=&quot;highlighter-rouge&quot;&gt;semi&lt;/code&gt;
        &lt;ul&gt;
          &lt;li&gt;3つのデータセット (ISIC2017, ISIC Archive, Interactive Atlas) からなる7544枚の学習画像
            &lt;ul&gt;
              &lt;li&gt;melanoma分類ではこのデータ群で学習したほうがAUCスコアが良かった&lt;/li&gt;
            &lt;/ul&gt;
          &lt;/li&gt;
        &lt;/ul&gt;
      &lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
&lt;/ul&gt;

&lt;h3 id=&quot;使用モデル&quot;&gt;使用モデル&lt;/h3&gt;

&lt;ul&gt;
  &lt;li&gt;ImageNetモデルのfine-tuning
    &lt;ul&gt;
      &lt;li&gt;ResNet-101&lt;/li&gt;
      &lt;li&gt;Inception-v4&lt;/li&gt;
      &lt;li&gt;~Inception-ResNet~
        &lt;ul&gt;
          &lt;li&gt;計算コストが大きいがスコアは微増しただけだったため使用を見送った&lt;/li&gt;
        &lt;/ul&gt;
      &lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
  &lt;li&gt;各クラス独立に学習を行っていたが、3クラス分類に変更した&lt;/li&gt;
&lt;/ul&gt;

&lt;h2 id=&quot;4-どうやって有効だと検証した&quot;&gt;4. どうやって有効だと検証した？&lt;/h2&gt;

&lt;ul&gt;
  &lt;li&gt;ベースラインのVGG16とResNet101やInception-v4を比べる&lt;/li&gt;
  &lt;li&gt;標準的なサイズの画像 (224x224) とより大きな高解像度の画像を入力したときの精度の比較&lt;/li&gt;
  &lt;li&gt;class-weightやsample-weightの考慮&lt;/li&gt;
  &lt;li&gt;curriculum-learningの有無
    &lt;ul&gt;
      &lt;li&gt;最初は簡単なデータで学習させ、学習が進んだら難しいデータで学習させる&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
  &lt;li&gt;最終conv層をそのままニューラルネットにするかSVMにするか&lt;/li&gt;
  &lt;li&gt;年齢や性別といった患者データを使うかどうか&lt;/li&gt;
  &lt;li&gt;用いるoptimizerの比較&lt;/li&gt;
  &lt;li&gt;異なるper-sample normalizationnの実施&lt;/li&gt;
  &lt;li&gt;アンサンブルやスタッキングの有無&lt;/li&gt;
&lt;/ul&gt;

&lt;h2 id=&quot;5-議論はある&quot;&gt;5. 議論はある？&lt;/h2&gt;
&lt;h3 id=&quot;効果がなかったこと&quot;&gt;効果がなかったこと&lt;/h3&gt;
&lt;ul&gt;
  &lt;li&gt;画像の解像度について
    &lt;ul&gt;
      &lt;li&gt;高解像度は効果なし&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
  &lt;li&gt;class-weightやsample-weightについて
    &lt;ul&gt;
      &lt;li&gt;no weighting was the best weighting&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
  &lt;li&gt;validationデータにおけるearly stoppingについて
    &lt;ul&gt;
      &lt;li&gt;特にスコアに対するインパクトはなかった&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
  &lt;li&gt;患者データの利用
    &lt;ul&gt;
      &lt;li&gt;効果があるときと無い時がある&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
  &lt;li&gt;curriculum learningの使用
    &lt;ul&gt;
      &lt;li&gt;シンプルなトレーニングのほうがよかった&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
  &lt;li&gt;セグメンテーションの情報の利用
    &lt;ul&gt;
      &lt;li&gt;今回は使えなかったけど、使うと効果が出るのではと考えられている&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
&lt;/ul&gt;

&lt;h3 id=&quot;効果があったこと&quot;&gt;効果があったこと&lt;/h3&gt;
&lt;ul&gt;
  &lt;li&gt;deepなモデルと規模の大きいデータセットを用いると効果が大きい&lt;/li&gt;
  &lt;li&gt;data augmentationは必須
    &lt;ul&gt;
      &lt;li&gt;テスト時にもdata augmentationするとよい (test time augmentation 的な)&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
  &lt;li&gt;mean subtractionは有効
    &lt;ul&gt;
      &lt;li&gt;標準偏差で割るnormalizationはスコアを悪化させた&lt;/li&gt;
      &lt;li&gt;Inception-v4では確認できた。ResNetについては不明&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
  &lt;li&gt;Stackingは有効&lt;/li&gt;
&lt;/ul&gt;

&lt;h2 id=&quot;論文情報リンク&quot;&gt;論文情報・リンク&lt;/h2&gt;

&lt;ul&gt;
  &lt;li&gt;&lt;a href=&quot;https://arxiv.org/abs/1703.04819&quot;&gt;Menegola, Afonso, et al. “RECOD titans at ISIC challenge 2017.” arXiv preprint arXiv:1703.04819 (2017).&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;</content><author><name></name></author><summary type="html">1. どんなもの？</summary></entry><entry><title type="html">Contextual Augmentation: Data Augmentation by Words with Paradigmatic Relations</title><link href="https://shunk031.github.io/paper-survey/summary/nip/Contextual-Augmentation-Data-Augmentation-by-Words-with-Paradigmatic-Relations" rel="alternate" type="text/html" title="Contextual Augmentation: Data Augmentation by Words with Paradigmatic Relations" /><published>2018-05-27T00:00:00+00:00</published><updated>2018-05-27T00:00:00+00:00</updated><id>https://shunk031.github.io/paper-survey/summary/nip/Contextual-Augmentation-Data-Augmentation-by-Words-with-Paradigmatic-Relations</id><content type="html" xml:base="https://shunk031.github.io/paper-survey/summary/nip/Contextual-Augmentation-Data-Augmentation-by-Words-with-Paradigmatic-Relations">&lt;h2 id=&quot;1-どんなもの&quot;&gt;1. どんなもの？&lt;/h2&gt;

&lt;p&gt;文脈および感情値などの条件を考慮した単語置き換えでdata augmentationを実現するContextual Augmentationを提案&lt;/p&gt;

&lt;h2 id=&quot;2-先行研究と比べてどこがすごいの&quot;&gt;2. 先行研究と比べてどこがすごいの？&lt;/h2&gt;

&lt;p&gt;ニューラルネットベースのモデルは高い精度を示すが過学習しやすい。
Data augmentationは汎化性能を向上させるテクニックであり、画像認識分野では回転やフリップなどを用いてデータのかさ増しを行っている。&lt;/p&gt;

&lt;p&gt;しかしながら自然言語処理に対するdata augmentationの適用法は限られている。
一般的にはWordNetなどを用いた単語の置き換えやルールベースの手法が用いられるが、ドメインに特化している場合も多く、一般性が失われたものとなっている。&lt;/p&gt;

&lt;p&gt;本研究ではbi-directional言語モデル(LM)を用いて、文脈を考慮した単語置き換えでdata augmentationを実現するContextual Augmentationを提案している。&lt;/p&gt;

&lt;h2 id=&quot;3-技術や手法のキモはどこにある&quot;&gt;3. 技術や手法の”キモ”はどこにある？&lt;/h2&gt;

&lt;p&gt;&lt;img src=&quot;/paper-survey/assets/img/nlp/Contextual-Augmentation-Data-Augmentation-by-Words-with-Paradigmatic-Relations/figure1.png&quot; alt=&quot;Figure 1&quot; /&gt;&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;文脈を考慮した単語予測
    &lt;ul&gt;
      &lt;li&gt;bi-directional LSTMを用いて、文脈に基づいて文中の位置 &lt;script type=&quot;math/tex&quot;&gt;i&lt;/script&gt; におけるword probabilityを計算&lt;/li&gt;
      &lt;li&gt;オンラインでdata augmentationするための単語をサンプリングする&lt;/li&gt;
      &lt;li&gt;data augmentationを制御するパラメータとしてtemperature &lt;script type=&quot;math/tex&quot;&gt;\tau&lt;/script&gt; を導入する&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
  &lt;li&gt;感情値などの条件を考慮
    &lt;ul&gt;
      &lt;li&gt;LMにおいて &lt;code class=&quot;highlighter-rouge&quot;&gt;good&lt;/code&gt; と &lt;code class=&quot;highlighter-rouge&quot;&gt;bad&lt;/code&gt; は近い表現になりやすく、反義語がdata augmentationに使われてしまう場合がある
        &lt;ul&gt;
          &lt;li&gt;label-conditional LMを用いてpositive/negativeなどのラベルを考慮し、反義語を制御する&lt;/li&gt;
        &lt;/ul&gt;
      &lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
&lt;/ul&gt;

&lt;h2 id=&quot;4-どうやって有効だと検証した&quot;&gt;4. どうやって有効だと検証した？&lt;/h2&gt;

&lt;p&gt;SST(SST2, SST5)、Subj、MPQA、RT、TRECの各データセットを用いている。モデルはLSTM、CNNをそれぞれ利用し、提案手法であるContextual Augmentationの効果を確認している。&lt;/p&gt;

&lt;h2 id=&quot;5-議論はあるか&quot;&gt;5. 議論はあるか？&lt;/h2&gt;

&lt;p&gt;&lt;img src=&quot;/paper-survey/assets/img/nlp/Contextual-Augmentation-Data-Augmentation-by-Words-with-Paradigmatic-Relations/figure2.png&quot; alt=&quot;Figure 2&quot; /&gt;&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;LMによって予測された単語は必ずしもシノニムになっていない&lt;/li&gt;
  &lt;li&gt;label-conditional LMを用いると、ラベルの性質に沿った単語の予測がなされている&lt;/li&gt;
&lt;/ul&gt;

&lt;h2 id=&quot;6-次に読むべき論文はあるか&quot;&gt;6. 次に読むべき論文はあるか？&lt;/h2&gt;

&lt;ul&gt;
  &lt;li&gt;シノニムを利用した単語置換によるdata augmentation
    &lt;ul&gt;
      &lt;li&gt;&lt;a href=&quot;http://papers.nips.cc/paper/5782-character-level-convolutional-networks-for-text-classifica&quot;&gt;Zhang, Xiang, Junbo Zhao, and Yann LeCun. “Character-level convolutional networks for text classification.” Advances in neural information processing systems. 2015.&lt;/a&gt;&lt;/li&gt;
      &lt;li&gt;&lt;a href=&quot;http://www.aclweb.org/anthology/D15-1306&quot;&gt;Wang, William Yang, and Diyi Yang. “That’s So Annoying!!!: A Lexical and Frame-Semantic Embedding Based Data Augmentation Approach to Automatic Categorization of Annoying Behaviors using# petpeeve Tweets.” Proceedings of the 2015 Conference on Empirical Methods in Natural Language Processing. 2015.&lt;/a&gt;&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
  &lt;li&gt;文法推論 (grammar induction)を用いたdata augmentation
    &lt;ul&gt;
      &lt;li&gt;&lt;a href=&quot;https://arxiv.org/abs/1606.03622&quot;&gt;Jia, Robin, and Percy Liang. “Data recombination for neural semantic parsing.” arXiv preprint arXiv:1606.03622 (2016).&lt;/a&gt;&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
  &lt;li&gt;タスク固有のヒューリスティックを利用したdata augmentation
    &lt;ul&gt;
      &lt;li&gt;&lt;a href=&quot;https://dl.acm.org/citation.cfm?id=1609091&quot;&gt;Fürstenau, Hagen, and Mirella Lapata. “Semi-supervised semantic role labeling.” Proceedings of the 12th Conference of the European Chapter of the Association for Computational Linguistics. Association for Computational Linguistics, 2009.&lt;/a&gt;&lt;/li&gt;
      &lt;li&gt;&lt;a href=&quot;http://www.aclweb.org/anthology/W17-3529&quot;&gt;Kafle, Kushal, Mohammed Yousefhussien, and Christopher Kanan. “Data augmentation for visual question answering.” Proceedings of the 10th International Conference on Natural Language Generation. 2017.&lt;/a&gt;&lt;/li&gt;
      &lt;li&gt;&lt;a href=&quot;http://www.aclweb.org/anthology/K17-2010&quot;&gt;Silfverberg, Miikka, et al. “Data Augmentation for Morphological Reinflection.” Proceedings of the CoNLL SIGMORPHON 2017 Shared Task: Universal Morphological Reinflection (2017): 90-99.&lt;/a&gt;&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
  &lt;li&gt;Autoencoderを用いたdata augmentation
    &lt;ul&gt;
      &lt;li&gt;&lt;a href=&quot;http://www.aclweb.org/anthology/K17-2002&quot;&gt;Bergmanis, Toms, et al. “Training Data Augmentation for Low-Resource Morphological Inflection.” Proceedings of the CoNLL SIGMORPHON 2017 Shared Task: Universal Morphological Reinflection (2017): 31-39.&lt;/a&gt;&lt;/li&gt;
      &lt;li&gt;&lt;a href=&quot;http://www.aaai.org/ocs/index.php/AAAI/AAAI17/paper/download/14299/14261&quot;&gt;Xu, Weidi, et al. “Variational Autoencoder for Semi-Supervised Text Classification.” AAAI. 2017.&lt;/a&gt;&lt;/li&gt;
      &lt;li&gt;&lt;a href=&quot;http://proceedings.mlr.press/v70/hu17e.html&quot;&gt;Hu, Zhiting, et al. “Toward controlled generation of text.” International Conference on Machine Learning. 2017.&lt;/a&gt;&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
  &lt;li&gt;Encoder-Decoderを用いたdata augmentation
    &lt;ul&gt;
      &lt;li&gt;&lt;a href=&quot;https://arxiv.org/abs/1606.07947&quot;&gt;Kim, Yoon, and Alexander M. Rush. “Sequence-level knowledge distillation.” arXiv preprint arXiv:1606.07947 (2016).&lt;/a&gt;&lt;/li&gt;
      &lt;li&gt;&lt;a href=&quot;https://arxiv.org/abs/1511.06709&quot;&gt;Sennrich, Rico, Barry Haddow, and Alexandra Birch. “Improving neural machine translation models with monolingual data.” arXiv preprint arXiv:1511.06709 (2015).&lt;/a&gt;&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
  &lt;li&gt;本研究に一番近い立ち位置の先行研究
    &lt;ul&gt;
      &lt;li&gt;&lt;a href=&quot;https://dl.acm.org/citation.cfm?id=2002793&quot;&gt;Kolomiyets, Oleksandr, Steven Bethard, and Marie-Francine Moens. “Model-portability experiments for textual temporal analysis.” Proceedings of the 49th Annual Meeting of the Association for Computational Linguistics: Human Language Technologies: short papers-Volume 2. Association for Computational Linguistics, 2011.&lt;/a&gt;&lt;/li&gt;
      &lt;li&gt;&lt;a href=&quot;https://arxiv.org/abs/1705.00440&quot;&gt;Fadaee, Marzieh, Arianna Bisazza, and Christof Monz. “Data augmentation for low-resource neural machine translation.” arXiv preprint arXiv:1705.00440 (2017).&lt;/a&gt;&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
&lt;/ul&gt;

&lt;h3 id=&quot;論文情報リンク&quot;&gt;論文情報・リンク&lt;/h3&gt;

&lt;ul&gt;
  &lt;li&gt;&lt;a href=&quot;https://arxiv.org/abs/1805.06201&quot;&gt;Kobayashi, Sosuke. “Contextual Augmentation: Data Augmentation by Words with Paradigmatic Relations.” arXiv preprint arXiv:1805.06201 (2018).&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;</content><author><name></name></author><summary type="html">1. どんなもの？</summary></entry><entry><title type="html">Hierarchical Attention Networks for Document Classification</title><link href="https://shunk031.github.io/paper-survey/summary/nlp/Hierarchical-Attention-Networks-for-Document-Classification" rel="alternate" type="text/html" title="Hierarchical Attention Networks for Document Classification" /><published>2018-05-06T00:00:00+00:00</published><updated>2018-05-06T00:00:00+00:00</updated><id>https://shunk031.github.io/paper-survey/summary/nlp/Hierarchical-Attention-Networks-for-Document-Classification</id><content type="html" xml:base="https://shunk031.github.io/paper-survey/summary/nlp/Hierarchical-Attention-Networks-for-Document-Classification">&lt;h2 id=&quot;1-どんなもの&quot;&gt;1. どんなもの？&lt;/h2&gt;

&lt;p&gt;Attentionを用いてより重要な単語・文に注目させ、同時に文書の階層的構造を捉えることができるHierarchal Attention Network (HAN) を提案&lt;/p&gt;

&lt;h2 id=&quot;2-先行研究と比べてどこがすごいの&quot;&gt;2. 先行研究と比べてどこがすごいの？&lt;/h2&gt;

&lt;p&gt;一般的にテキスト分類をする場合、全ての単語が文書の意味を捉えるのに重要であるとは限らない。&lt;/p&gt;

&lt;p&gt;本研究では単語レベル、文レベルでAttentionを適用することにより重要な単語および文を抽出し、
同時に文書の階層的な構造を捉えることができるHierarchal Attention Network (HAN) を提案している。&lt;/p&gt;

&lt;h2 id=&quot;3-技術や手法のキモはどこにある&quot;&gt;3. 技術や手法の”キモ”はどこにある？&lt;/h2&gt;

&lt;p&gt;&lt;img src=&quot;/paper-survey/assets/img/nlp/Hierarchical-Attention-Networks-for-Document-Classification/figure2.png&quot; alt=&quot;Figure 2&quot; /&gt;&lt;/p&gt;

&lt;p&gt;GRUによってエンコードされたembeddingに対して、単語レベル、文レベルの2つのレベルでAttentionを適用する。&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;Hierarchal Attention Network (HAN)
    &lt;ul&gt;
      &lt;li&gt;GRU-based sequence encoder
        &lt;ul&gt;
          &lt;li&gt;Word Encoder&lt;/li&gt;
          &lt;li&gt;Sentence Attention&lt;/li&gt;
        &lt;/ul&gt;
      &lt;/li&gt;
      &lt;li&gt;Hierarchal Attention
        &lt;ul&gt;
          &lt;li&gt;Word Attention&lt;/li&gt;
          &lt;li&gt;Sentence Encoder&lt;/li&gt;
        &lt;/ul&gt;
      &lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;Attentionの計算はエンコードされたベクトルに対して1層のMLPを用いて隠れ層ベクトルの重要度を算出する。&lt;/p&gt;

&lt;h2 id=&quot;4-どうやって有効だと検証した&quot;&gt;4. どうやって有効だと検証した？&lt;/h2&gt;

&lt;p&gt;複数のデータセットと複数のベースラインを用いて提案手法であるHANの性能を評価している。
Attentionの効果を見るため、Hierarchal Network(HN)にaverage-poolingを使うHN-AVE、およびmax-poolingを使うHN-MAX、そして提案手法であるHNにAttentionを組み込んだHN-ATTの性能についても比較している。&lt;/p&gt;

&lt;h3 id=&quot;データセットについて&quot;&gt;データセットについて&lt;/h3&gt;

&lt;table&gt;
  &lt;thead&gt;
    &lt;tr&gt;
      &lt;th&gt;Data set&lt;/th&gt;
      &lt;th&gt;# of classes&lt;/th&gt;
      &lt;th&gt;# of documents&lt;/th&gt;
      &lt;th&gt;Author&lt;/th&gt;
    &lt;/tr&gt;
  &lt;/thead&gt;
  &lt;tbody&gt;
    &lt;tr&gt;
      &lt;td&gt;Yelp 2013&lt;/td&gt;
      &lt;td&gt;5&lt;/td&gt;
      &lt;td&gt;335,018&lt;/td&gt;
      &lt;td&gt;&lt;a href=&quot;http://www.aclweb.org/anthology/D15-1167&quot;&gt;Tang et al., 2015&lt;/a&gt;&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td&gt;Yelp 2014&lt;/td&gt;
      &lt;td&gt;5&lt;/td&gt;
      &lt;td&gt;1,125,457&lt;/td&gt;
      &lt;td&gt;&lt;a href=&quot;http://www.aclweb.org/anthology/D15-1167&quot;&gt;Tang et al., 2015&lt;/a&gt;&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td&gt;Yelp 2015&lt;/td&gt;
      &lt;td&gt;5&lt;/td&gt;
      &lt;td&gt;1,569,264&lt;/td&gt;
      &lt;td&gt;&lt;a href=&quot;http://www.aclweb.org/anthology/D15-1167&quot;&gt;Tang et al., 2015&lt;/a&gt;&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td&gt;IMDB review&lt;/td&gt;
      &lt;td&gt;10&lt;/td&gt;
      &lt;td&gt;348,415&lt;/td&gt;
      &lt;td&gt;&lt;a href=&quot;https://dl.acm.org/citation.cfm?id=2623758&quot;&gt;Diao et al., 2014&lt;/a&gt;&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td&gt;Yahoo Answer&lt;/td&gt;
      &lt;td&gt;10&lt;/td&gt;
      &lt;td&gt;1,450,000&lt;/td&gt;
      &lt;td&gt;&lt;a href=&quot;https://arxiv.org/abs/1509.01626&quot;&gt;Zhang et al., 2015&lt;/a&gt;&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td&gt;Amazon review&lt;/td&gt;
      &lt;td&gt;5&lt;/td&gt;
      &lt;td&gt;3,650,000&lt;/td&gt;
      &lt;td&gt;&lt;a href=&quot;https://arxiv.org/abs/1509.01626&quot;&gt;Zhang et al., 2015&lt;/a&gt;&lt;/td&gt;
    &lt;/tr&gt;
  &lt;/tbody&gt;
&lt;/table&gt;

&lt;h3 id=&quot;ベースラインについて&quot;&gt;ベースラインについて&lt;/h3&gt;

&lt;ul&gt;
  &lt;li&gt;Linear methods
    &lt;ul&gt;
      &lt;li&gt;BoW and BoW + TFIDF&lt;/li&gt;
      &lt;li&gt;n-grams and n-grams + TFIDF&lt;/li&gt;
      &lt;li&gt;Bag-of-means&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
  &lt;li&gt;SVMs
    &lt;ul&gt;
      &lt;li&gt;Text Features&lt;/li&gt;
      &lt;li&gt;Average SG&lt;/li&gt;
      &lt;li&gt;SSWE&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
  &lt;li&gt;Neural Network methods
    &lt;ul&gt;
      &lt;li&gt;CNN-word&lt;/li&gt;
      &lt;li&gt;CNN_char&lt;/li&gt;
      &lt;li&gt;LSTM&lt;/li&gt;
      &lt;li&gt;Conv-GRNN&lt;/li&gt;
      &lt;li&gt;LSTM-GRNN&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
  &lt;li&gt;Hierarchal Network
    &lt;ul&gt;
      &lt;li&gt;HN-AVE&lt;/li&gt;
      &lt;li&gt;HN-MAX&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
&lt;/ul&gt;

&lt;h2 id=&quot;5-議論はあるか&quot;&gt;5. 議論はあるか？&lt;/h2&gt;

&lt;p&gt;&lt;img src=&quot;/paper-survey/assets/img/nlp/Hierarchical-Attention-Networks-for-Document-Classification/figure5.png&quot; alt=&quot;Figure 5&quot; /&gt;&lt;/p&gt;

&lt;p&gt;Figure 5の最初の文書でホタテを気に入らないような文章がある場合、単文だけを見ると、これは否定的なコメントだと感じられる。
しかし、提案手法ではこの文章の文脈を見て、これが肯定的な評価であり、この文を無視することを選択していることが示されている。&lt;/p&gt;

&lt;h2 id=&quot;6-次に読むべき論文はあるか&quot;&gt;6. 次に読むべき論文はあるか？&lt;/h2&gt;

&lt;ul&gt;
  &lt;li&gt;Attentionについて
    &lt;ul&gt;
      &lt;li&gt;&lt;a href=&quot;https://arxiv.org/abs/1409.0473&quot;&gt;Bahdanau, Dzmitry, Kyunghyun Cho, and Yoshua Bengio. “Neural machine translation by jointly learning to align and translate.” arXiv preprint arXiv:1409.0473 (2014).&lt;/a&gt;&lt;/li&gt;
      &lt;li&gt;&lt;a href=&quot;http://www.jmlr.org/proceedings/papers/v37/xuc15.pdf&quot;&gt;Xu, Kelvin, et al. “Show, attend and tell: Neural image caption generation with visual attention.” International Conference on Machine Learning. 2015.&lt;/a&gt;&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
&lt;/ul&gt;

&lt;h3 id=&quot;論文情報リンク&quot;&gt;論文情報・リンク&lt;/h3&gt;

&lt;ul&gt;
  &lt;li&gt;&lt;a href=&quot;http://www.aclweb.org/anthology/N16-1174&quot;&gt;Yang, Zichao, et al. “Hierarchical attention networks for document classification.” Proceedings of the 2016 Conference of the North American Chapter of the Association for Computational Linguistics: Human Language Technologies. 2016.&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;</content><author><name></name></author><summary type="html">1. どんなもの？</summary></entry><entry><title type="html">Utilizing Visual Forms of Japanese Characters for Neural Review Classification</title><link href="https://shunk031.github.io/paper-survey/summary/nlp/Utilizing-Visual-Forms-of-Japanese-Characters-for-Neural-Review-Classification" rel="alternate" type="text/html" title="Utilizing Visual Forms of Japanese Characters for Neural Review Classification" /><published>2018-04-30T00:00:00+00:00</published><updated>2018-04-30T00:00:00+00:00</updated><id>https://shunk031.github.io/paper-survey/summary/nlp/Utilizing-Visual-Forms-of-Japanese-Characters-for-Neural-Review-Classification</id><content type="html" xml:base="https://shunk031.github.io/paper-survey/summary/nlp/Utilizing-Visual-Forms-of-Japanese-Characters-for-Neural-Review-Classification">&lt;h2 id=&quot;1-どんなもの&quot;&gt;1. どんなもの？&lt;/h2&gt;

&lt;p&gt;文字の見た目を考慮した文字embeddingを用いて日本語の評判分析を行う&lt;/p&gt;

&lt;h2 id=&quot;2-先行研究と比べてどこがすごいの&quot;&gt;2. 先行研究と比べてどこがすごいの？&lt;/h2&gt;

&lt;p&gt;日本語や中国語の文字は表意文字であり、文字自身が意味を持っている。通常の自然言語処理の手法では、文字の見た目の情報は無視し、文字IDの羅列として扱う。
本研究では表意文字や記号の形状を考慮した日本語の評判分析を行うモデルを提案している。&lt;/p&gt;

&lt;h2 id=&quot;3-技術や手法のキモはどこにある&quot;&gt;3. 技術や手法の”キモ”はどこにある？&lt;/h2&gt;

&lt;p&gt;&lt;img src=&quot;/paper-survey/assets/img/nlp/Utilizing-Visual-Forms-of-Japanese-Characters-for-Neural-Review-Classification/figure2.png&quot; alt=&quot;Figure 2&quot; /&gt;&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;Character-based Hierarchal Attention Networks (HAN) をベースとしたモデル
    &lt;ul&gt;
      &lt;li&gt;HANと比べて文字embeddingのパラメータ数が大幅に減少している&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
  &lt;li&gt;文字を文字画像に変換し、そこからConvolutional Neural Networks (CNN) を通して文字の形状情報を捉えた文字embeddingを取り出す&lt;/li&gt;
&lt;/ul&gt;

&lt;h2 id=&quot;4-どうやって有効だと検証した&quot;&gt;4. どうやって有効だと検証した？&lt;/h2&gt;

&lt;p&gt;6段階の評価と7カテゴリが付与されている&lt;a href=&quot;https://www.nii.ac.jp/dsc/idr/en/rakuten/rakuten.html&quot;&gt;Raluten Travel review&lt;/a&gt;を用いて提案手法の性能を評価している。
ベースラインとして先行研究のHANを利用し、前処理として&lt;a href=&quot;https://github.com/ikegami-yukino/neologdn&quot;&gt;neologdn&lt;/a&gt;を用いてNFKCのユニコード標準化を行っている。&lt;/p&gt;

&lt;h2 id=&quot;5-議論はあるか&quot;&gt;5. 議論はあるか？&lt;/h2&gt;

&lt;ul&gt;
  &lt;li&gt;Visual attentionを適用して評判分析の際に文字のどの部分に着目しているのか可視化したい&lt;/li&gt;
  &lt;li&gt;従来の部首の辞書を用いた特徴を利用すれば未知の文字に対しても有効に特徴を取得できるのではないだろうか&lt;/li&gt;
&lt;/ul&gt;

&lt;h2 id=&quot;6-次に読むべき論文はあるか&quot;&gt;6. 次に読むべき論文はあるか？&lt;/h2&gt;

&lt;ul&gt;
  &lt;li&gt;HANについて
    &lt;ul&gt;
      &lt;li&gt;&lt;a href=&quot;http://www.aclweb.org/anthology/N16-1174&quot;&gt;Yang, Zichao, et al. “Hierarchical attention networks for document classification.” Proceedings of the 2016 Conference of the North American Chapter of the Association for Computational Linguistics: Human Language Technologies. 2016.&lt;/a&gt;&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
&lt;/ul&gt;

&lt;h3 id=&quot;論文情報リンク&quot;&gt;論文情報・リンク&lt;/h3&gt;

&lt;ul&gt;
  &lt;li&gt;&lt;a href=&quot;http://www.aclweb.org/anthology/I17-2064&quot;&gt;Toyama, Yota, Makoto Miwa, and Yutaka Sasaki. “Utilizing Visual Forms of Japanese Characters for Neural Review Classification.” Proceedings of the Eighth International Joint Conference on Natural Language Processing (Volume 2: Short Papers). Vol. 2. 2017.&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;</content><author><name></name></author><summary type="html">1. どんなもの？</summary></entry><entry><title type="html">Realistic Evaluation of Semi-Supervised Learning Algorithms</title><link href="https://shunk031.github.io/paper-survey/summary/cv/Realistic-Evaluation-of-Semi-Supervised-Learning-Algorithms" rel="alternate" type="text/html" title="Realistic Evaluation of Semi-Supervised Learning Algorithms" /><published>2018-04-28T00:00:00+00:00</published><updated>2018-04-28T00:00:00+00:00</updated><id>https://shunk031.github.io/paper-survey/summary/cv/Realistic-Evaluation-of-Semi-Supervised-Learning-Algorithms</id><content type="html" xml:base="https://shunk031.github.io/paper-survey/summary/cv/Realistic-Evaluation-of-Semi-Supervised-Learning-Algorithms">&lt;h2 id=&quot;1-どんなもの&quot;&gt;1. どんなもの？&lt;/h2&gt;

&lt;p&gt;現在SoTAである半教師あり学習のアルゴリズムについて、平等なテスト環境で性能を比較した。&lt;/p&gt;

&lt;h2 id=&quot;2-先行研究と比べてどこがすごいの&quot;&gt;2. 先行研究と比べてどこがすごいの？&lt;/h2&gt;

&lt;p&gt;Deep neural networkを学習させるためには大量の教師データが必要になるが、実際はデータが取りづらかったり、コストがかかる。
そこで教師ラベルのないデータセットも有効に活用する、半教師あり学習(SSL)が提案されている。&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;/paper-survey/assets/img/cv/Realistic-Evaluation-of-Semi-Supervised-Learning-Algorithms/figure1.png&quot; alt=&quot;Figure 1&quot; /&gt;&lt;/p&gt;

&lt;p&gt;先行研究で成果を上げているモデルは実際の使用環境を想定したモデルになっているかが疑問点としてあげられている。
本研究では現在デファクトスタンダートである半教師あり学習アルゴリズムに対して、それぞれ現実世界を想定した平等なテスト環境で性能を比較している。&lt;/p&gt;

&lt;h2 id=&quot;3-技術や手法のキモはどこにある&quot;&gt;3. 技術や手法の”キモ”はどこにある？&lt;/h2&gt;

&lt;p&gt;従来の半教師あり学習の評価方法を見直し、現実世界での適用を想定した以下の評価方法を用いて先行研究のモデルを評価した。&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;Shared Implementation
    &lt;ul&gt;
      &lt;li&gt;パラメータの初期化方法やデータの前処理、augmentation、正則化等を標準化する&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
  &lt;li&gt;High-Quality Supervised Baseline
    &lt;ul&gt;
      &lt;li&gt;SSLのゴールは &lt;script type=&quot;math/tex&quot;&gt;\mathcal{D}&lt;/script&gt; と &lt;script type=&quot;math/tex&quot;&gt;\mathcal{D}_{UL}&lt;/script&gt; を用いて学習させたモデルが、 &lt;script type=&quot;math/tex&quot;&gt;\mathcal{D}&lt;/script&gt; のみを用いて学習したモデルより良い精度を出すことである&lt;/li&gt;
      &lt;li&gt;そこで比較対象であるベースラインのモデルは &lt;script type=&quot;math/tex&quot;&gt;\mathcal{D}&lt;/script&gt; のみを用いて学習させるべき&lt;/li&gt;
      &lt;li&gt;ベースラインのモデルのパラメータ探索もSSLモデルと同様の回数探索するように設定&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
  &lt;li&gt;Comparison to Transfer Learning
    &lt;ul&gt;
      &lt;li&gt;学習済みモデルをfine-tuningした結果はあまり報告されないので、本研究ではベースラインとして精度を報告する&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
  &lt;li&gt;Consider Class Distribution Mismatch
    &lt;ul&gt;
      &lt;li&gt;ラベル付きデータとラベルなしデータの分布の違いによる影響について報告する&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
  &lt;li&gt;Varying the Amount of Labeled and Unlabeled Data
    &lt;ul&gt;
      &lt;li&gt;ラベルなしデータは巨大である(インターネット上から取得)場合か、医療画像のようにデータの規模が小さい場合が考えられる&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
  &lt;li&gt;Realistically Small Validation Set
    &lt;ul&gt;
      &lt;li&gt;先行研究ではtrainingセットの中から一部ラベルを落としたデータを用いて学習させ、validationセットでモデルのチューニングをしていた。このときラベル有りデータの数はvalidationセットのほうが遥かに多い&lt;/li&gt;
      &lt;li&gt;現実世界ではラベルを多く含むデータセットで学習を行うため、先行研究の評価方法では実践的な評価ができていないため、本研究ではtrainingセットより小さいvalidationセットを用いてパラメータをチューニングする&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
&lt;/ul&gt;

&lt;h2 id=&quot;4-どうやって有効だと検証した&quot;&gt;4. どうやって有効だと検証した？&lt;/h2&gt;

&lt;h3 id=&quot;使用したsslアルゴリズムについて&quot;&gt;使用したSSLアルゴリズムについて&lt;/h3&gt;

&lt;table&gt;
  &lt;thead&gt;
    &lt;tr&gt;
      &lt;th&gt;Method&lt;/th&gt;
      &lt;th&gt;Type&lt;/th&gt;
      &lt;th&gt;Author&lt;/th&gt;
    &lt;/tr&gt;
  &lt;/thead&gt;
  &lt;tbody&gt;
    &lt;tr&gt;
      &lt;td&gt;Stochastic Perturbations&lt;/td&gt;
      &lt;td&gt;Consistency Regularization&lt;/td&gt;
      &lt;td&gt;&lt;a href=&quot;http://papers.nips.cc/paper/6332-regularization-with-stochastic-transformations-and-perturbations-for-deep-semi-supervised-learning&quot;&gt;Sajjadi et al., 2016&lt;/a&gt;&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td&gt;Ⅱ-Model&lt;/td&gt;
      &lt;td&gt;Consistency Regularization&lt;/td&gt;
      &lt;td&gt;&lt;a href=&quot;https://arxiv.org/abs/1610.02242&quot;&gt;Laine &amp;amp; Aila, 2017&lt;/a&gt;&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td&gt;Temporal Embsembling&lt;/td&gt;
      &lt;td&gt;Consistency Regularization&lt;/td&gt;
      &lt;td&gt;&lt;a href=&quot;https://arxiv.org/abs/1610.02242&quot;&gt;Laine &amp;amp; Aila, 2017&lt;/a&gt;&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td&gt;Mean Teacher&lt;/td&gt;
      &lt;td&gt;Consistency Regularization&lt;/td&gt;
      &lt;td&gt;&lt;a href=&quot;http://papers.nips.cc/paper/6719-mean-teachers-are-better-role-models-weight-averaged-consistency-targets-improve-semi-supervised-deep-learning-results&quot;&gt;Tarvainen &amp;amp; Valpola, 2017&lt;/a&gt;&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td&gt;Virtual Adversarial Training&lt;/td&gt;
      &lt;td&gt;Consistency Regularization&lt;/td&gt;
      &lt;td&gt;&lt;a href=&quot;https://arxiv.org/abs/1704.03976&quot;&gt;Miyato et al., 2017&lt;/a&gt;&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td&gt;Entropy-Based&lt;/td&gt;
      &lt;td&gt;Entropy-Based&lt;/td&gt;
      &lt;td&gt;&lt;a href=&quot;http://papers.nips.cc/paper/2740-semi-supervised-learning-by-entropy-minimization.pdf&quot;&gt;Grandvalet &amp;amp; Bengio, 2005&lt;/a&gt;&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td&gt;Pseudo-Labeling&lt;/td&gt;
      &lt;td&gt;Pseudo-Labeling&lt;/td&gt;
      &lt;td&gt;&lt;a href=&quot;https://www.kaggle.com/blobs/download/forum-message-attachment-files/746/pseudo_label_final.pdf&quot;&gt;Lee, 2013&lt;/a&gt;&lt;/td&gt;
    &lt;/tr&gt;
  &lt;/tbody&gt;
&lt;/table&gt;

&lt;h3 id=&quot;評価方法について&quot;&gt;評価方法について&lt;/h3&gt;

&lt;ul&gt;
  &lt;li&gt;Reproduction
    &lt;ul&gt;
      &lt;li&gt;ベースモデルにWide ResNet (WRN-28-2) を使用&lt;/li&gt;
      &lt;li&gt;Google Cloud Machine Learning’s hyperparameter tuning serviceを用いてGaussian Process-based black box optimizationを行った&lt;/li&gt;
      &lt;li&gt;評価用データセットとしてSVHNとCIFAR-10を使用&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
  &lt;li&gt;Fully-Supervised Baselines&lt;/li&gt;
  &lt;li&gt;Transfer Learning&lt;/li&gt;
  &lt;li&gt;Class Distribution Mismatch&lt;/li&gt;
  &lt;li&gt;Varying Data Amounts&lt;/li&gt;
  &lt;li&gt;Small Validation Sets&lt;/li&gt;
&lt;/ul&gt;

&lt;h2 id=&quot;5-議論はあるか&quot;&gt;5. 議論はあるか？&lt;/h2&gt;

&lt;ul&gt;
  &lt;li&gt;SSLの各アルゴリズムに対して分布が違うラベルなしデータを学習に使うと学習が上手く進まなかった&lt;/li&gt;
  &lt;li&gt;ラベルありデータと同様の分布からサンプリングされるラベルなしデータを使用すべきである&lt;/li&gt;
&lt;/ul&gt;

&lt;h2 id=&quot;6-次に読むべき論文はあるか&quot;&gt;6. 次に読むべき論文はあるか？&lt;/h2&gt;

&lt;ul&gt;
  &lt;li&gt;Stochastic Perturbationsについて
    &lt;ul&gt;
      &lt;li&gt;&lt;a href=&quot;http://papers.nips.cc/paper/6332-regularization-with-stochastic-transformations-and-perturbations-for-deep-semi-supervised-learning&quot;&gt;Sajjadi, Mehdi, Mehran Javanmardi, and Tolga Tasdizen. “Regularization with stochastic transformations and perturbations for deep semi-supervised learning.” Advances in Neural Information Processing Systems. 2016.&lt;/a&gt;&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
  &lt;li&gt;Ⅱ-Model / Temporal Ensemblingについて
    &lt;ul&gt;
      &lt;li&gt;&lt;a href=&quot;https://arxiv.org/abs/1610.02242&quot;&gt;Laine, Samuli, and Timo Aila. “Temporal ensembling for semi-supervised learning.” arXiv preprint arXiv:1610.02242 (2016).&lt;/a&gt;&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
  &lt;li&gt;Mean Teacherについて
    &lt;ul&gt;
      &lt;li&gt;&lt;a href=&quot;http://papers.nips.cc/paper/6719-mean-teachers-are-better-role-models-weight-averaged-consistency-targets-improve-semi-supervised-deep-learning-results&quot;&gt;Tarvainen, Antti, and Harri Valpola. “Mean teachers are better role models: Weight-averaged consistency targets improve semi-supervised deep learning results.” Advances in neural information processing systems. 2017.&lt;/a&gt;&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
  &lt;li&gt;Virtual Adversarial Trainingについて
    &lt;ul&gt;
      &lt;li&gt;&lt;a href=&quot;https://arxiv.org/abs/1704.03976&quot;&gt;Miyato, Takeru, et al. “Virtual adversarial training: a regularization method for supervised and semi-supervised learning.” arXiv preprint arXiv:1704.03976 (2017).&lt;/a&gt;&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
  &lt;li&gt;Entropy-basedな手法について
    &lt;ul&gt;
      &lt;li&gt;&lt;a href=&quot;http://papers.nips.cc/paper/2740-semi-supervised-learning-by-entropy-minimization.pdf&quot;&gt;Grandvalet, Yves, and Yoshua Bengio. “Semi-supervised learning by entropy minimization.” Advances in neural information processing systems. 2005.&lt;/a&gt;&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
  &lt;li&gt;Pseudo-Labelingについて
    &lt;ul&gt;
      &lt;li&gt;&lt;a href=&quot;https://www.kaggle.com/blobs/download/forum-message-attachment-files/746/pseudo_label_final.pdf&quot;&gt;Lee, Dong-Hyun. “Pseudo-label: The simple and efficient semi-supervised learning method for deep neural networks.” Workshop on Challenges in Representation Learning, ICML. Vol. 3. 2013.&lt;/a&gt;&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
&lt;/ul&gt;

&lt;h3 id=&quot;論文情報リンク&quot;&gt;論文情報・リンク&lt;/h3&gt;

&lt;ul&gt;
  &lt;li&gt;&lt;a href=&quot;https://arxiv.org/abs/1804.09170&quot;&gt;Oliver, Avital, et al. “Realistic Evaluation of Semi-Supervised Learning Algorithms.” arXiv preprint arXiv:1804.09170 (2018).&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;</content><author><name></name></author><summary type="html">1. どんなもの？</summary></entry><entry><title type="html">Word Embedding Perturbation for Sentence Classification</title><link href="https://shunk031.github.io/paper-survey/summary/nlp/Word-Embedding-Perturbation-for-Sentence-Classification" rel="alternate" type="text/html" title="Word Embedding Perturbation for Sentence Classification" /><published>2018-04-27T00:00:00+00:00</published><updated>2018-04-27T00:00:00+00:00</updated><id>https://shunk031.github.io/paper-survey/summary/nlp/Word-Embedding-Perturbation-for-Sentence-Classification</id><content type="html" xml:base="https://shunk031.github.io/paper-survey/summary/nlp/Word-Embedding-Perturbation-for-Sentence-Classification">&lt;h2 id=&quot;1-どんなもの&quot;&gt;1. どんなもの？&lt;/h2&gt;

&lt;p&gt;入力される単語embeddingに対していくつかのノイズで摂動を与え、文書分類における精度の検証する&lt;/p&gt;

&lt;h2 id=&quot;2-先行研究と比べてどこがすごいの&quot;&gt;2. 先行研究と比べてどこがすごいの？&lt;/h2&gt;

&lt;p&gt;自然言語処理では単語は離散的であり、連続空間では単語表現を変更できないため、一般的にdata augmentationは利用されてこなかった。&lt;/p&gt;

&lt;p&gt;近年ではシソーラスを用いた単語の置換や、2つの単語間の依存関係の向きを逆にすることで学習データを2倍に増やす手法が提案されている。これらは外部の知識体系が必要であったり、洗練されたNLPツールが必要である。&lt;/p&gt;

&lt;p&gt;またBag-of-Wordsに対してランダムにdropoutさせる手法を用いて、文書分類で性能を向上させたものがある。しかしながらノイズの与え方を比較していなかったり、単語の分散表現空間に対して適用していない問題がある。&lt;/p&gt;

&lt;p&gt;本研究では連続空間上の単語embeddingに対して複数種類のノイズで摂動を与え、文書分類における精度の検証を行っている。&lt;/p&gt;

&lt;h2 id=&quot;3-技術や手法のキモはどこにある&quot;&gt;3. 技術や手法の”キモ”はどこにある？&lt;/h2&gt;

&lt;p&gt;Word embeddingレイヤーに対して &lt;code class=&quot;highlighter-rouge&quot;&gt;word embedding perturbation&lt;/code&gt; を適用。&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;Gaussian Noise
    &lt;ul&gt;
      &lt;li&gt;入力される単語embeddingに対して、ガウスノイズ &lt;script type=&quot;math/tex&quot;&gt;e&lt;/script&gt; を適用する&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
&lt;/ul&gt;

&lt;script type=&quot;math/tex; mode=display&quot;&gt;X_{emb} \leftarrow X_{emb} \odot e, e \sim \mathcal{N}(I, \sigma^{2}I)&lt;/script&gt;

&lt;ul&gt;
  &lt;li&gt;Bernoulli Noise Augmentation
    &lt;ul&gt;
      &lt;li&gt;先行研究で提案されているDropoutを参考に、確率 &lt;script type=&quot;math/tex&quot;&gt;p&lt;/script&gt; で単語embeddingを0にする&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
&lt;/ul&gt;

&lt;script type=&quot;math/tex; mode=display&quot;&gt;X_{emb} \leftarrow \frac{1}{p} X_{emb} \odot e, e \sim \mathcal{B}(n, p)&lt;/script&gt;

&lt;ul&gt;
  &lt;li&gt;Adversarial Training
    &lt;ul&gt;
      &lt;li&gt;loss関数が最大になるような方向にノイズを加える&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
&lt;/ul&gt;

&lt;script type=&quot;math/tex; mode=display&quot;&gt;e \leftarrow e + \sigma \frac{g}{||g||}, g = \nabla_{e} L(X:\theta)&lt;/script&gt;

&lt;p&gt;文書の意味を考慮したrandom perturbationについて。&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;Word Dropout
    &lt;ul&gt;
      &lt;li&gt;ベルヌーイ分布に従ってランダムに単語 &lt;script type=&quot;math/tex&quot;&gt;X&lt;/script&gt; をdropoutさせる&lt;/li&gt;
      &lt;li&gt;dropoutさせた単語は &lt;code class=&quot;highlighter-rouge&quot;&gt;UNK&lt;/code&gt; と同じ表現にする&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
&lt;/ul&gt;

&lt;script type=&quot;math/tex; mode=display&quot;&gt;X \leftarrow X \odot \overrightarrow{e}, \overrightarrow{e} \sim \mathcal{B}(n, p)&lt;/script&gt;

&lt;ul&gt;
  &lt;li&gt;Semantic Dropout
    &lt;ul&gt;
      &lt;li&gt;単語embeddingの各次元はそれぞれセマンティックな意味を持っていると考えられる&lt;/li&gt;
      &lt;li&gt;単語間の共起を覚えさせるのではなく意味的な特徴を捉えてほしいため、単語embeddingの各次元をランダムにdropoutさせる&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
  &lt;li&gt;Adversarial Noise
    &lt;ul&gt;
      &lt;li&gt;Gaussian adversarial noise
        &lt;ul&gt;
          &lt;li&gt;ガウス分布から &lt;script type=&quot;math/tex&quot;&gt;e&lt;/script&gt; をサンプルして、adversarial trainingを適用&lt;/li&gt;
        &lt;/ul&gt;
      &lt;/li&gt;
      &lt;li&gt;Bernoulli adversarial noise
        &lt;ul&gt;
          &lt;li&gt;ベルヌーイ分布から &lt;script type=&quot;math/tex&quot;&gt;e&lt;/script&gt; をサンプルして、adversarial trainingを適用&lt;/li&gt;
          &lt;li&gt;Adversarial dropoutを適用&lt;/li&gt;
        &lt;/ul&gt;
      &lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
&lt;/ul&gt;

&lt;h2 id=&quot;4-どうやって有効だと検証した&quot;&gt;4. どうやって有効だと検証した？&lt;/h2&gt;

&lt;p&gt;Moview review (MR)、The Stanford Sentiment Treebank (SST2)、Customer revirew (CR)、Question type (TREC)、SemEval2010 Task8 (RE)、Answer selection (TreeQA) の
データセットを用いてノイズを用いた各data augmentationの効果を確認している。&lt;/p&gt;

&lt;p&gt;モデルはmulti-channel CNN (Kim, 2014)を利用しており、300次元の学習済みword2vecを単語embeddingとして用いている。&lt;/p&gt;

&lt;h2 id=&quot;5-議論はあるか&quot;&gt;5. 議論はあるか？&lt;/h2&gt;

&lt;ul&gt;
  &lt;li&gt;連続性ノイズと離散性ノイズ
    &lt;ul&gt;
      &lt;li&gt;連続性ノイズ (Gaussian noise, Gaussian adversarial noise) のほうが僅かに離散性ノイズ (Bernoulli noise, Adversarial dropout) より良い結果になった&lt;/li&gt;
      &lt;li&gt;離散性ノイズは効果が強すぎたと考えられる&lt;/li&gt;
      &lt;li&gt;連続性ノイズのほうがエントロピーが大きく、学習に効果があると考えられる&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
  &lt;li&gt;学習データを少なくしたときの効果
    &lt;ul&gt;
      &lt;li&gt;データセットが少ない場合に、ベースラインよりもノイズの摂動が効果を発揮していることが分かる&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;&lt;img src=&quot;/paper-survey/assets/img/nlp/Word-Embedding-Perturbation-for-Sentence-Classification/figure1.png&quot; alt=&quot;Figure 1&quot; /&gt;&lt;/p&gt;

&lt;h2 id=&quot;6-次に読むべき論文はあるか&quot;&gt;6. 次に読むべき論文はあるか？&lt;/h2&gt;

&lt;ul&gt;
  &lt;li&gt;シソーラスを用いた単語の置換
    &lt;ul&gt;
      &lt;li&gt;&lt;a href=&quot;https://arxiv.org/abs/1502.01710&quot;&gt;Zhang, Xiang, and Yann LeCun. “Text understanding from scratch.” arXiv preprint arXiv:1502.01710 (2015).&lt;/a&gt;&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
  &lt;li&gt;単語間の依存関係に着目したdata augmentation
    &lt;ul&gt;
      &lt;li&gt;&lt;a href=&quot;https://arxiv.org/abs/1601.03651&quot;&gt;Xu, Yan, et al. “Improved relation classification by deep recurrent neural networks with data augmentation.” arXiv preprint arXiv:1601.03651 (2016).&lt;/a&gt;&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
  &lt;li&gt;BoWに対してdropoutを適用
    &lt;ul&gt;
      &lt;li&gt;&lt;a href=&quot;http://www.aclweb.org/anthology/P15-1162&quot;&gt;Iyyer, Mohit, et al. “Deep unordered composition rivals syntactic methods for text classification.” Proceedings of the 53rd Annual Meeting of the Association for Computational Linguistics and the 7th International Joint Conference on Natural Language Processing (Volume 1: Long Papers). Vol. 1. 2015.&lt;/a&gt;&lt;/li&gt;
      &lt;li&gt;&lt;a href=&quot;https://link.springer.com/chapter/10.1007/978-3-319-50496-4_59&quot;&gt;Zhang, Dongxu, Tianyi Luo, and Dong Wang. “Learning from LDA using deep neural networks.” Natural Language Understanding and Intelligent Applications. Springer, Cham, 2016. 657-664.&lt;/a&gt;&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
  &lt;li&gt;Adversarial Dropout
    &lt;ul&gt;
      &lt;li&gt;&lt;a href=&quot;https://arxiv.org/abs/1707.03631&quot;&gt;Park, Sungrae, et al. “Adversarial Dropout for Supervised and Semi-supervised Learning.” arXiv preprint arXiv:1707.03631 (2017).&lt;/a&gt;&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
  &lt;li&gt;ベースラインの multi-channel CNN
    &lt;ul&gt;
      &lt;li&gt;&lt;a href=&quot;https://arxiv.org/abs/1408.5882&quot;&gt;Kim, Yoon. “Convolutional neural networks for sentence classification.” arXiv preprint arXiv:1408.5882 (2014).&lt;/a&gt;&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
&lt;/ul&gt;

&lt;h3 id=&quot;論文情報リンク&quot;&gt;論文情報・リンク&lt;/h3&gt;

&lt;ul&gt;
  &lt;li&gt;&lt;a href=&quot;https://arxiv.org/pdf/1804.08166&quot;&gt;Zhang, Dongxu, and Zhichao Yang. “Word Embedding Perturbation for Sentence Classification.” arXiv preprint arXiv:1804.08166 (2018).&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;</content><author><name></name></author><summary type="html">1. どんなもの？</summary></entry><entry><title type="html">Learning to Compute Word Embeddings On the Fly</title><link href="https://shunk031.github.io/paper-survey/summary/nlp/Learning-to-Compute-Word-Embeddings-On-the-Fly" rel="alternate" type="text/html" title="Learning to Compute Word Embeddings On the Fly" /><published>2018-04-01T00:00:00+00:00</published><updated>2018-04-01T00:00:00+00:00</updated><id>https://shunk031.github.io/paper-survey/summary/nlp/Learning-to-Compute-Word-Embeddings-On-the-Fly</id><content type="html" xml:base="https://shunk031.github.io/paper-survey/summary/nlp/Learning-to-Compute-Word-Embeddings-On-the-Fly">&lt;h2 id=&quot;1-どんなもの&quot;&gt;1. どんなもの？&lt;/h2&gt;

&lt;p&gt;OOV問題に対してWordNetの単語定義文をエンコードし未知語に対処する，On the Fly Embdddingsを提案．&lt;/p&gt;

&lt;h2 id=&quot;2-先行研究と比べてどこがすごいの&quot;&gt;2. 先行研究と比べてどこがすごいの？&lt;/h2&gt;

&lt;p&gt;自然言語では頻繁に出現する単語もあるが，ほとんどがZipfian分布に従うような，あまり現れない単語から形成されている．
こうした単語の低頻度の単語はout-of-vocabulary (OOV) 問題として扱われる．&lt;/p&gt;

&lt;p&gt;先行研究ではボキャブラリ外の単語を固定のランダムベクトルで代用する研究があり，効果を示している．
またスペル情報からBi-directional LSTMを用いて，ボキャブラリ外の単語を一般化する先行研究がある．
本研究に最も近い先行研究では，対象となる単語埋め込みに近い辞書定義埋め込みを生成するものがある．&lt;/p&gt;

&lt;p&gt;本研究では特定のタスク対して辞書定義エンコーダをend-to-endで学習を行い，
エンコードした定義文と補助ベクトルを用いてボキャブラリ外の未知語に対応するモデルを提案する．&lt;/p&gt;

&lt;h2 id=&quot;3-技術や手法のキモはどこにある&quot;&gt;3. 技術や手法の”キモ”はどこにある？&lt;/h2&gt;

&lt;p&gt;&lt;img src=&quot;/paper-survey/assets/img/nlp/Learning-to-Compute-Word-Embeddings-On-The-Fly/figure1.png&quot; alt=&quot;Figure 1&quot; /&gt;&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;On the Fly embeddings
    &lt;ul&gt;
      &lt;li&gt;辞書 (WordNet) 定義文をエンコードする &lt;em&gt;definition reader&lt;/em&gt;
        &lt;ul&gt;
          &lt;li&gt;simple mean pooling (MP)&lt;/li&gt;
          &lt;li&gt;mean pooling (MP-L)
            &lt;ul&gt;
              &lt;li&gt;学習可能な行列を辞書内単語ベクトルに掛ける&lt;/li&gt;
            &lt;/ul&gt;
          &lt;/li&gt;
          &lt;li&gt;LSTMの最終ステート&lt;/li&gt;
        &lt;/ul&gt;
      &lt;/li&gt;
      &lt;li&gt;補助ベクトル
        &lt;ul&gt;
          &lt;li&gt;WordNetの定義分からなるベクトル表現&lt;/li&gt;
          &lt;li&gt;単語の文字列情報 (&lt;code class=&quot;highlighter-rouge&quot;&gt;word&lt;/code&gt; -&amp;gt; &lt;code class=&quot;highlighter-rouge&quot;&gt;w&lt;/code&gt;, &lt;code class=&quot;highlighter-rouge&quot;&gt;o&lt;/code&gt;, &lt;code class=&quot;highlighter-rouge&quot;&gt;r&lt;/code&gt;, &lt;code class=&quot;highlighter-rouge&quot;&gt;d&lt;/code&gt;)&lt;/li&gt;
          &lt;li&gt;大規模なデータセットで学習済みのGloVeベクトル&lt;/li&gt;
        &lt;/ul&gt;
      &lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
&lt;/ul&gt;

&lt;h2 id=&quot;4-どうやって有効だと検証した&quot;&gt;4. どうやって有効だと検証した？&lt;/h2&gt;
&lt;p&gt;提案手法に対して Question Answering，Semantic Entailment Classification，Language Modellingの3つのタスクで評価を行っている．&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;Question Answering
    &lt;ul&gt;
      &lt;li&gt;Stanford Question Answering Dataset (SQuAD)を用いて提案手法の評価を行っている．&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
  &lt;li&gt;Semantic Entailment Classification
    &lt;ul&gt;
      &lt;li&gt;Stanford Natural Language Inference (SNLI) コーパスとMulti-Genre Natural Language Inference (MultiNLI) コーパスを用いて提案手法の評価を行っている．&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
  &lt;li&gt;Language Modelling
    &lt;ul&gt;
      &lt;li&gt;One Billion Words (OBW) language modellingタスクで提案手法の評価を行っている．&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
&lt;/ul&gt;

&lt;h2 id=&quot;5-議論はあるか&quot;&gt;5. 議論はあるか？&lt;/h2&gt;

&lt;ul&gt;
  &lt;li&gt;Future work
    &lt;ul&gt;
      &lt;li&gt;複数単語からなる熟語は考慮されていない
        &lt;ul&gt;
          &lt;li&gt;&lt;code class=&quot;highlighter-rouge&quot;&gt;give up&lt;/code&gt; などの熟語&lt;/li&gt;
          &lt;li&gt;&lt;code class=&quot;highlighter-rouge&quot;&gt;San Francisco&lt;/code&gt; のような地名&lt;/li&gt;
        &lt;/ul&gt;
      &lt;/li&gt;
      &lt;li&gt;辞書定義中の未知語への対応&lt;/li&gt;
      &lt;li&gt;循環参照してしまっている単語への対応
        &lt;ul&gt;
          &lt;li&gt;(例 &lt;code class=&quot;highlighter-rouge&quot;&gt;hoge&lt;/code&gt;: &lt;code class=&quot;highlighter-rouge&quot;&gt;fuga&lt;/code&gt;のこと，&lt;code class=&quot;highlighter-rouge&quot;&gt;fuga&lt;/code&gt;: &lt;code class=&quot;highlighter-rouge&quot;&gt;hoge&lt;/code&gt;のこと)&lt;/li&gt;
        &lt;/ul&gt;
      &lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
&lt;/ul&gt;

&lt;h2 id=&quot;6-次に読むべき論文はあるか&quot;&gt;6. 次に読むべき論文はあるか？&lt;/h2&gt;

&lt;ul&gt;
  &lt;li&gt;OOV単語に対して固定のランダムベクトルを適用
    &lt;ul&gt;
      &lt;li&gt;&lt;a href=&quot;https://arxiv.org/abs/1703.00993&quot;&gt;Dhingra, Bhuwan, et al. “A comparative study of word embeddings for reading comprehension.” arXiv preprint arXiv:1703.00993 (2017).&lt;/a&gt;&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
  &lt;li&gt;スペルからOOV単語を一般化する試み
    &lt;ul&gt;
      &lt;li&gt;&lt;a href=&quot;https://arxiv.org/abs/1508.02096&quot;&gt;Ling, Wang, et al. “Finding function in form: Compositional character models for open vocabulary word representation.” arXiv preprint arXiv:1508.02096 (2015).&lt;/a&gt;&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
  &lt;li&gt;対象となる単語埋め込みに近い辞書定義埋め込みを生成
    &lt;ul&gt;
      &lt;li&gt;&lt;a href=&quot;http://www.aclweb.org/anthology/Q16-1002&quot;&gt;Hill, Felix, et al. “Learning to Understand Phrases by Embedding the Dictionary.” Transactions of the Association for Computational Linguistics 4 (2016): 17-30.&lt;/a&gt;&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
&lt;/ul&gt;

&lt;h3 id=&quot;論文情報リンク&quot;&gt;論文情報・リンク&lt;/h3&gt;

&lt;ul&gt;
  &lt;li&gt;&lt;a href=&quot;https://arxiv.org/abs/1706.00286&quot;&gt;Bahdanau, Dzmitry, et al. “Learning to Compute Word Embeddings On the Fly.” arXiv preprint arXiv:1706.00286 (2017).&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;</content><author><name></name></author><summary type="html">1. どんなもの？</summary></entry></feed>